{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Academy Awards Analysis\n",
    "## Investigating Trends in Oscar-Winning Movies\n",
    "### Author: Judd Jacobs\n",
    "\n",
    "This project analyzes historical **Academy Award-winning films** using data from **Wikipedia** (scraped via BeautifulSoup) and the **Kaggle Oscar Awards dataset**. The analysis explores:\n",
    "- üèÜ **Best Picture trends by genre**\n",
    "- üé≠ **Box office revenue & IMDb ratings**\n",
    "- üìà **Long-term trends in Oscar-winning films**\n",
    "- ‚òÅÔ∏è **Stretch Goal**: **Word Cloud analysis of Wikipedia movie summaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# #I need to check the below code to see if it is necessary\n",
    "# # Set plotting style\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# # Ensure necessary NLTK components are downloaded\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇ Data Collection: Scraping Wikipedia\n",
    "We will extract **Best Picture winners** and relevant metadata (title, year, genre) using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BeautifulSoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Fetch page content\u001b[39;00m\n\u001b[1;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(wiki_url)\n\u001b[0;32m----> 6\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Extract all tables in the page\u001b[39;00m\n\u001b[1;32m      9\u001b[0m tables \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikitable\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BeautifulSoup' is not defined"
     ]
    }
   ],
   "source": [
    "# Define Wikipedia URL for Best Picture winners\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/Academy_Award_for_Best_Picture\"\n",
    "\n",
    "# Fetch page content\n",
    "response = requests.get(wiki_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Extract all tables in the page\n",
    "tables = soup.find_all(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Select the correct table (adjust index if needed)\n",
    "best_picture_table = tables[1]\n",
    "\n",
    "# Extract data from table rows\n",
    "movies_data = []\n",
    "rows = best_picture_table.find_all(\"tr\")\n",
    "\n",
    "# Loop through rows to extract relevant data\n",
    "for row in rows[1:]:  # Skip header row\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) >= 2:\n",
    "        year = cols[0].text.strip()\n",
    "        title = cols[1].text.strip()\n",
    "        movies_data.append([year, title])\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "movies_df = pd.DataFrame(movies_data, columns=[\"Year\", \"Best Picture Winner\"])\n",
    "\n",
    "# Display the first few rows\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Data Collection: Kaggle Dataset\n",
    "We will load additional Oscar award data from a structured Kaggle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kaggle dataset\n",
    "kaggle_df = pd.read_csv(\"oscar_awards.csv\")\n",
    "\n",
    "# Display dataset structure\n",
    "kaggle_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ† Data Cleaning & Storage\n",
    "We will clean and merge Wikipedia & Kaggle data, then store it in an **SQLite database**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Wikipedia data\n",
    "movies_df[\"Year\"] = movies_df[\"Year\"].str.extract(r\"(\\d{4})\").astype(float)\n",
    "\n",
    "# Merge Wikipedia and Kaggle data\n",
    "merged_df = pd.merge(movies_df, kaggle_df, left_on=\"Best Picture Winner\", right_on=\"Film\", how=\"left\")\n",
    "\n",
    "# Save to SQLite database\n",
    "conn = sqlite3.connect(\"academy_awards.db\")\n",
    "merged_df.to_sql(\"best_picture_winners\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"Data successfully stored in SQLite database!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Exploratory Data Analysis\n",
    "We will explore trends in **Best Picture winners** by genre and other relevant statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique genres in Kaggle dataset\n",
    "print(kaggle_df[\"Genre\"].unique())\n",
    "\n",
    "# Count of Best Picture winners by genre\n",
    "genre_counts = kaggle_df[\"Genre\"].value_counts()\n",
    "\n",
    "# Plot the genre distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=genre_counts.index, y=genre_counts.values, palette=\"Blues_r\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Number of Wins\")\n",
    "plt.title(\"Best Picture Wins by Genre\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí∞ Box Office & IMDb Ratings\n",
    "We will analyze **box office revenue** and IMDb ratings of Best Picture winners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Box Office Revenue vs IMDb Ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=kaggle_df[\"BoxOffice\"], y=kaggle_df[\"IMDb Rating\"], hue=kaggle_df[\"Year\"], palette=\"coolwarm\")\n",
    "plt.xlabel(\"Box Office Revenue (in millions)\")\n",
    "plt.ylabel(\"IMDb Rating\")\n",
    "plt.title(\"Box Office Revenue vs IMDb Ratings for Best Picture Winners\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Stretch Goal: Word Cloud (Wikipedia Movie Summaries)\n",
    "If Wikipedia summaries are accessible, generate a **word cloud** from commonly used words in movie descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Wikipedia summary text (replace with actual summaries if available)\n",
    "sample_text = \"This is a sample summary of a Best Picture-winning film. It tells the story of love, ambition, and success.\"\n",
    "\n",
    "# Tokenize & remove stopwords\n",
    "tokens = word_tokenize(sample_text.lower())\n",
    "filtered_words = [word for word in tokens if word.isalnum() and word not in stopwords.words(\"english\")]\n",
    "\n",
    "# Generate Word Cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(filtered_words))\n",
    "\n",
    "# Display Word Cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud of Wikipedia Movie Summaries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscars = pd.read_csv(\"data/oscars.csv\", sep='\\t', on_bad_lines='skip')\n",
    "oscars = oscars.dropna()\n",
    "oscars = oscars.drop_duplicates()\n",
    "oscars = oscars.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean movie metadata\n",
    "def clean_movie_data(df):\n",
    "    \"\"\"\n",
    "    Handle missing values and standardize column names in the movie dataset.\n",
    "    \"\"\"\n",
    "    df.dropna(subset=[\"title\", \"release_year\"], inplace=True)\n",
    "    df.fillna({\"box_office\": 0, \"runtime\": df[\"runtime\"].median()}, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Clean speech transcripts (stretch goal)\n",
    "# def preprocess_speech_text(text):\n",
    "#     \"\"\"\n",
    "#     Tokenize and clean Oscar acceptance speech text for word frequency analysis.\n",
    "#     \"\"\"\n",
    "#     nltk.download(\"stopwords\")\n",
    "#     nltk.download(\"punkt\")\n",
    "#     tokens = word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
    "#     filtered_words = [word for word in tokens if word.isalnum() and word not in stopwords.words(\"english\")]\n",
    "#     return \" \".join(filtered_words)\n",
    "\n",
    "# speech_df[\"cleaned_speech\"] = speech_df[\"speech_text\"].apply(preprocess_speech_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Store Data in SQLite Database\n",
    "conn = sqlite3.connect(\"academy_awards.db\")\n",
    "awards_df.to_sql(\"awards\", conn, if_exists=\"replace\", index=False)\n",
    "speech_df.to_sql(\"speeches\", conn, if_exists=\"replace\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: SQL Queries & Analysis\n",
    "## Query genres of Best Picture winners over decades\n",
    "query = \"\"\"\n",
    "SELECT genre, COUNT(*) AS num_wins, strftime('%Y', award_year) AS decade\n",
    "FROM awards\n",
    "WHERE category = 'Best Picture'\n",
    "GROUP BY genre, decade\n",
    "ORDER BY decade ASC;\n",
    "\"\"\"\n",
    "genre_trends_df = pd.read_sql(query, conn)\n",
    "\n",
    "## Query word frequency in acceptance speeches\n",
    "query = \"\"\"\n",
    "SELECT cleaned_speech FROM speeches;\n",
    "\"\"\"\n",
    "speech_texts = pd.read_sql(query, conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Data Visualization\n",
    "## Bar Chart - Best Picture Wins by Genre\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=\"genre\", y=\"num_wins\", hue=\"decade\", data=genre_trends_df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Best Picture Wins by Genre Over Decades\")\n",
    "plt.show()\n",
    "\n",
    "## Scatter Plot - Box Office vs IMDb Ratings\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.scatterplot(x=\"box_office\", y=\"imdb_rating\", hue=\"decade\", data=awards_df)\n",
    "plt.title(\"Box Office Revenue vs IMDb Ratings for Oscar Winners\")\n",
    "plt.show()\n",
    "\n",
    "## Word Cloud - Common Words in Acceptance Speeches\n",
    "all_text = \" \".join(speech_texts[\"cleaned_speech\"])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(all_text)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Most Common Words in Oscar Acceptance Speeches\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Conclusion & Interpretation\n",
    "\"\"\"\n",
    "- The bar chart shows which genres have dominated the Best Picture category over time.\n",
    "- The scatter plot identifies any correlation between box office revenue and audience reception (IMDb ratings).\n",
    "- The word cloud highlights common themes in Oscar speeches, reflecting industry trends and sentiments. (stretch goal)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Analysis (examples)\n",
    "- In this analysis, we explored the relationship between the race of law enforcement officers and the race of the drivers they stop. Our goal was to see if there‚Äôs any indication of bias in traffic stops based on the racial identity of the officers. To do this, we used a chi-squared test for independence, which helps us understand whether there‚Äôs a meaningful connection between these two groups.\n",
    "\n",
    "### Results of the Chi-Squared Test\n",
    "- **Chi-Squared Statistic:** We calculated a chi-squared statistic of 122.92. This high number shows that there‚Äôs a significant difference between the actual number of stops for different racial groups and what we would expect to see if there were no connection between the officer's race and the driver's race. In other words, this suggests that the patterns we observe in the data are unlikely to be just a coincidence.\n",
    "\n",
    "- **P-Value:** The p-value we found was about 8.20e-17, which is extremely low. This tells us that the result is statistically significant since it‚Äôs much lower than the usual thresholds (like 0.05 or 0.01). A low p-value means we have strong evidence against the idea that there‚Äôs no connection between the officer's race and the driver's race.\n",
    "\n",
    "### Interpretation of Findings\n",
    "- The results show a strong connection between the race of the officer and the race of the driver being stopped. This means that a driver's chances of being stopped may change depending on the officer's race, suggesting there might be some bias in how traffic stops are carried out.\n",
    "\n",
    "### Implications\n",
    "- These findings are important for understanding how race plays a role in law enforcement. They suggest that different racial groups might be treated differently by officers during traffic stops. It's crucial to address these biases to ensure fairness and equality in policing.\n",
    "\n",
    "### Conclusion\n",
    "- The strong evidence from the chi-squared statistic and p-value emphasizes the importance of further examining law enforcement practices. Police leaders and community advocacy groups should take these findings into account when reviewing policies and training programs designed to reduce racial bias in policing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
