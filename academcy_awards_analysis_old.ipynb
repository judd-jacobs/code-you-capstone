{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academy Awards Analysis üé¨\n",
    "## Investigating Trends in Oscar-Winning Movies\n",
    "### Author: Judd Jacobs\n",
    "\n",
    "This project analyzes historical **Academy Award-winning films** using data from **Wikipedia**, **The Movie Database (TMDb)**, and **The Open Movie Database (OMDb)**.\n",
    "\n",
    "## **Key Analysis Areas**\n",
    "- **Best Picture trends by genre** (from Wikipedia Scrape & TMDb API) üèÜ\n",
    "- **Box office revenue & IMDb ratings** (OMDb API) üé≠\n",
    "- **Long-term trends in Oscar-winning films** üìà"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1:** Import necessary Python Libraries üíΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from urllib.parse import quote\n",
    "import time\n",
    "\n",
    "# # Import NLTK libraries are currently a strech goal for future development\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# # Ensure necessary NLTK components are downloaded\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2:** Data Acquisition üóÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scraping** Wikipedia\n",
    "Extract **Best Picture winners** and relevant metadata using:\n",
    "- **`pandas.read_html()`** to extract the table structure.\n",
    "- **`BeautifulSoup`** to identify \"winning\" rows based on Wikipedia background color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia URL for Best Picture winners\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_Academy_Award%E2%80%93winning_films\"\n",
    "\n",
    "# Use pandas to extract the table\n",
    "tables = pd.read_html(wiki_url)\n",
    "\n",
    "# Select the correct table, adjusting the index, as needed - which is currently the first table at index 0 (as of 20250317)\n",
    "best_picture_wikipedia = tables[0]\n",
    "\n",
    "# Convert the table to a DataFrame\n",
    "best_picture_wikipedia = pd.DataFrame(best_picture_wikipedia)\n",
    "\n",
    "# Print the first few rows to ensure the correct table was selected\n",
    "best_picture_wikipedia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Wikipedia table with BeautifulSoup\n",
    "response_wikipedia = requests.get(wiki_url)\n",
    "soup_wikipedia = BeautifulSoup(response_wikipedia.text, \"html.parser\")\n",
    "wikipedia_table = soup_wikipedia.find_all(\"table\", {\"class\": \"wikitable\"})[0]\n",
    "\n",
    "# Extract all rows\n",
    "rows = wikipedia_table.find_all(\"tr\")\n",
    "\n",
    "# List to store \"Winner\" status\n",
    "winning_status = []\n",
    "\n",
    "# Loop through rows and check for background color \"#EEDD82\" skipping the header row\n",
    "for row in rows[1:]:\n",
    "    style = row.get(\"style\", \"\")\n",
    "    \n",
    "    # Check if the row has the background color for winners and remove spaces for consistency\n",
    "    if \"background:#EEDD82\" in style.replace(\" \", \"\"):\n",
    "        winning_status.append(\"Winner\")\n",
    "    else:\n",
    "        winning_status.append(\"Nominee\")\n",
    "\n",
    "# Ensure the list length matches the DataFrame\n",
    "if len(winning_status) == len(best_picture_wikipedia):\n",
    "    best_picture_wikipedia[\"Status\"] = winning_status\n",
    "else:\n",
    "    print(\"List length does not match DataFrame length\")\n",
    "\n",
    "# Normalize \"Status\" column and filter only winners\n",
    "best_picture_winners = best_picture_wikipedia[best_picture_wikipedia[\"Status\"] == \"Winner\"]\n",
    "\n",
    "# Convert the table to a DataFrame\n",
    "best_picture_winners = pd.DataFrame(best_picture_winners)\n",
    "\n",
    "# Display updated DataFrame\n",
    "best_picture_winners.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Genres from TMDb API üé≠\n",
    "Use **The Movie Database (TMDb) API** to retrieve **movie genres** for Best Picture winners listed in Wikipedia Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the TMDB API keys stored in the .env file and define them here\n",
    "tmdb_api_key = os.getenv('TMDB_API_KEY')\n",
    "tmdb_api_read_access_token = os.getenv('TMBD_API_READ_ACCESS_TOKEN')\n",
    "\n",
    "tmdb_api_base_url = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "# Function to get genre mappings (ID -> Name)\n",
    "def get_genre_mapping() -> dict:\n",
    "    url = f\"{tmdb_api_base_url}/genre/movie/list?language=en-US\"\n",
    "    headers = {\"accept\": \"application/json\", \"Authorization\": f\"Bearer {tmdb_api_read_access_token}\"}\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"genres\" in data:\n",
    "        return {genre[\"id\"]: genre[\"name\"] for genre in data[\"genres\"]}\n",
    "    return {}\n",
    "\n",
    "# Function to query TMDB API and get genre names for movies\n",
    "def get_movie_genres(film_titles) -> dict:\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {tmdb_api_read_access_token}\"\n",
    "        }\n",
    "    \n",
    "    # Fetch genre ID-to-name mapping\n",
    "    genre_mapping = get_genre_mapping()\n",
    "\n",
    "    # Store results\n",
    "    movie_genres = {}\n",
    "\n",
    "    for title in film_titles:\n",
    "        # Encode spaces and special characters for use in URL\n",
    "        encoded_title = quote(title)\n",
    "        \n",
    "        url = f\"{tmdb_api_base_url}/search/movie?query={encoded_title}&include_adult=false&language=en-US&page=1\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "        \n",
    "        if \"results\" in data and data[\"results\"]:\n",
    "            # Ensure exact match\n",
    "            exact_match = next((movie for movie in data[\"results\"] if movie[\"title\"] == title), None)\n",
    "            \n",
    "            if exact_match:\n",
    "                genre_ids = exact_match[\"genre_ids\"]\n",
    "                genre_names = [genre_mapping.get(gid, \"Unknown Genre\") for gid in genre_ids]\n",
    "                movie_genres[title] = genre_names\n",
    "            else:\n",
    "                movie_genres[title] = [\"No exact match found\"]\n",
    "        else:\n",
    "            movie_genres[title] = [\"No results found\"]\n",
    "    \n",
    "    return movie_genres\n",
    "\n",
    "# Create a List of the movie titles from extracted Wikipedia data\n",
    "movie_titles = best_picture_winners[\"Film\"].tolist()\n",
    "\n",
    "# Get genre names for each movie\n",
    "genre_results = get_movie_genres(movie_titles)\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "genre_results = pd.DataFrame(list(genre_results.items()), columns=[\"Title\", \"Genres\"])\n",
    "genre_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Data from Wikipedia and TMDb üéûÔ∏è\n",
    "Merge data from Wikipedia and TMDb verifying column names for both DataFrames before merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm column names for both DataFrames\n",
    "print(\"best_picture_winners columns:\", best_picture_winners.columns.tolist())\n",
    "print(\"genre_results columns:\", genre_results.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge best_picture_winners and genre_results DataFrames on \"Film\"/\"Title\"\n",
    "best_picture_winners = best_picture_winners.merge(\n",
    "    genre_results,\n",
    "    left_on=\"Film\",\n",
    "    right_on=\"Title\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Drop the now redundant \"Title\" column\n",
    "best_picture_winners.drop(\"Title\", axis=1, inplace=True)\n",
    "\n",
    "# Split the genres into separate columns\n",
    "best_picture_winners = best_picture_winners.explode(\"Genres\")\n",
    "best_picture_winners = pd.concat([best_picture_winners, best_picture_winners[\"Genres\"].str.get_dummies()], axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "best_picture_winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Box Office Revenue from OMDb API üí∏\n",
    "Use **OMDb API** to fetch **box office revenue** for Best Picture winners and combine with Wikipedia and TMDb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in OMDb API Key\n",
    "omdb_api_key = os.getenv('OMDB_API_KEY')\n",
    "\n",
    "# Function to fetch box office revenue from OMDb API given a movie title\n",
    "def get_box_office(movie_title, api_key) -> str:\n",
    "    # Ensure spaces & special characters are URL-safe\n",
    "    encoded_title = quote(movie_title)\n",
    "    omdb_url = f\"http://www.omdbapi.com/?t={encoded_title}&apikey={api_key}\"\n",
    "    \n",
    "    try:\n",
    "        # Timeout to prevent hanging\n",
    "        response = requests.get(omdb_url, timeout=10)\n",
    "        # Raises an error for 4xx/5xx responses\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse JSON response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Handle API errors\n",
    "        if \"Error\" in data:\n",
    "            print(f\"OMDb API Error for {movie_title}: {data['Error']}\")\n",
    "            return \"N/A\"\n",
    "        # Return Box Office revenue or \"N/A\" if missing\n",
    "        return data.get(\"BoxOffice\", \"N/A\")\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Timeout error for {movie_title}. Skipping...\")\n",
    "        return \"Timeout\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request failed for {movie_title}: {e}\")\n",
    "        return \"API Error\"\n",
    "    except ValueError:\n",
    "        print(f\"Invalid JSON response for {movie_title}.\")\n",
    "        return \"JSON Error\"\n",
    "\n",
    "# Use the correct DataFrame (`best_picture_winners`)\n",
    "if \"Box Office Revenue\" not in best_picture_winners.columns:\n",
    "    best_picture_winners[\"Box Office Revenue\"] = \"\"\n",
    "\n",
    "# Apply function to each movie in the dataset (with a delay to avoid rate limits)\n",
    "for index, row in best_picture_winners.iterrows():\n",
    "    title = row[\"Film\"]\n",
    "    best_picture_winners.at[index, \"Box Office Revenue\"] = get_box_office(title, omdb_api_key)\n",
    "\n",
    "# Display updated DataFrame\n",
    "best_picture_winners.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3:** Data Cleaning & Storage üõ†\n",
    "Merged data will have some cleaning applied and then the cleaned dataset will be stored in a local **SQLite database**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset summary\n",
    "print(best_picture_winners.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(best_picture_winners.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with \"Unknown\"\n",
    "best_picture_winners['Genres'] = best_picture_winners['Genres'].fillna('Unknown')\n",
    "print(best_picture_winners.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address Year column values/formatting\n",
    "The \"Year\" variable has some values that are not years, but a combination of years (e.g., 2020/21). I have decided to retain only the first year listed and convert it to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first four-digit year and convert to integer\n",
    "# best_picture_winners[\"Year\"] = best_picture_winners[\"Year\"].str.extract(r\"(\\d{4})\")\n",
    "best_picture_winners[\"Year\"] = pd.to_numeric(best_picture_winners[\"Year\"], errors=\"coerce\")\n",
    "\n",
    "# Convert 'Box Office Revenue' to numeric, removing any non-numeric characters\n",
    "best_picture_winners['Box Office Revenue'] = pd.to_numeric(\n",
    "    best_picture_winners['Box Office Revenue'].replace(r'[\\$,]', '', regex=True), \n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "\n",
    "# Display cleaned DataFrame\n",
    "best_picture_winners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates and drop them\n",
    "duplicates = best_picture_winners.duplicated()\n",
    "print(f'Duplicate rows: {duplicates.sum()}')\n",
    "best_picture_winners = best_picture_winners.drop_duplicates()\n",
    "\n",
    "# Strip whitespace and convert to title case\n",
    "best_picture_winners['Film'] = best_picture_winners['Film'].str.strip().str.title()\n",
    "best_picture_winners['Genres'] = best_picture_winners['Genres'].str.strip().str.title()\n",
    "best_picture_winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cleaned data to local SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect(\"academy_awards.db\")\n",
    "# merged_df.to_sql(\"best_picture_winners\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# print(\"Data successfully stored in SQLite database!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are cells that might be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell was moved down from above and may eventually be removed\n",
    "# # Function to store movie data in SQLite\n",
    "# def store_movie_data(movie_data) -> None:\n",
    "#     # Create/connect to the database\n",
    "#     conn = sqlite3.connect(\"academy_awards.db\")\n",
    "#     cursor = conn.cursor()\n",
    "\n",
    "#     # Create table if it doesn't exist\n",
    "#     cursor.execute('''\n",
    "#         CREATE TABLE IF NOT EXISTS movies (\n",
    "#             id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#             film TEXT,\n",
    "#             release_date TEXT,\n",
    "#             overview TEXT,\n",
    "#             vote_average REAL,\n",
    "#             tmdb_id INTEGER UNIQUE\n",
    "#         )\n",
    "#     ''')\n",
    "\n",
    "#     # Extract movie details from API response\n",
    "#     if movie_data and movie_data.get(\"results\"):\n",
    "#         for movie in movie_data[\"results\"]:\n",
    "#             tmdb_id = movie.get(\"id\")\n",
    "#             title = movie.get(\"title\", \"Unknown\")\n",
    "#             release_date = movie.get(\"release_date\", \"N/A\")\n",
    "#             overview = movie.get(\"overview\", \"No description available.\")\n",
    "#             vote_average = movie.get(\"vote_average\", 0.0)\n",
    "\n",
    "#             # Insert or ignore if the movie already exists (prevents duplicate entries)\n",
    "#             cursor.execute('''\n",
    "#                 INSERT OR IGNORE INTO movies (tmdb_id, title, release_date, overview, vote_average)\n",
    "#                 VALUES (?, ?, ?, ?, ?)\n",
    "#             ''', (tmdb_id, title, release_date, overview, vote_average))\n",
    "\n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "\n",
    "# # Loop through each movie, fetch data, and store in the database\n",
    "# for movie in movie_titles:\n",
    "#     data = fetch_movie_data(movie)\n",
    "#     if data:\n",
    "#         store_movie_data(data)\n",
    "\n",
    "# print(\"Movie data successfully stored in SQLite database!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connect to the database\n",
    "# conn = sqlite3.connect(\"academy_awards.db\")\n",
    "\n",
    "# # Create a cursor object\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Execute the query and fetch all rows\n",
    "# cursor.execute(\"SELECT * FROM movies\")\n",
    "# rows = cursor.fetchall()\n",
    "\n",
    "# # Print the results\n",
    "# for row in rows:\n",
    "#     print(row)\n",
    "\n",
    "# # Close the connection\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis üìä\n",
    "We will explore trends in **Best Picture winners** by genre and other relevant statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Office Ratings üí∞\n",
    "We will analyze **box office revenue** and number of nominations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatter plot: Box Office Revenue vs IMDb Ratings\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(x=kaggle_df[\"BoxOffice\"], y=kaggle_df[\"IMDb Rating\"], hue=kaggle_df[\"Year\"], palette=\"coolwarm\")\n",
    "# plt.xlabel(\"Box Office Revenue (in millions)\")\n",
    "# plt.ylabel(\"IMDb Rating\")\n",
    "# plt.title(\"Box Office Revenue vs IMDb Ratings for Best Picture Winners\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goal: Word Cloud (Wikipedia Movie Summaries) ‚òÅÔ∏è\n",
    "If Wikipedia summaries are accessible, generate a **word cloud** from commonly used words in movie descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample Wikipedia summary text (replace with actual summaries if available)\n",
    "# sample_text = \"This is a sample summary of a Best Picture-winning film. It tells the story of love, ambition, and success.\"\n",
    "\n",
    "# # Tokenize & remove stopwords\n",
    "# tokens = word_tokenize(sample_text.lower())\n",
    "# filtered_words = [word for word in tokens if word.isalnum() and word not in stopwords.words(\"english\")]\n",
    "\n",
    "# # Generate Word Cloud\n",
    "# wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(filtered_words))\n",
    "\n",
    "# # Display Word Cloud\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Word Cloud of Wikipedia Movie Summaries\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oscars = pd.read_csv(\"data/oscars.csv\", sep='\\t', on_bad_lines='skip')\n",
    "# oscars = oscars.dropna()\n",
    "# oscars = oscars.drop_duplicates()\n",
    "# oscars = oscars.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Store Data in SQLite Database\n",
    "# conn = sqlite3.connect(\"academy_awards.db\")\n",
    "# awards_df.to_sql(\"awards\", conn, if_exists=\"replace\", index=False)\n",
    "# speech_df.to_sql(\"speeches\", conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: SQL Queries & Analysis\n",
    "# ## Query genres of Best Picture winners over decades\n",
    "# query = \"\"\"\n",
    "# SELECT genre, COUNT(*) AS num_wins, strftime('%Y', award_year) AS decade\n",
    "# FROM awards\n",
    "# WHERE category = 'Best Picture'\n",
    "# GROUP BY genre, decade\n",
    "# ORDER BY decade ASC;\n",
    "# \"\"\"\n",
    "# genre_trends_df = pd.read_sql(query, conn)\n",
    "\n",
    "# ## Query word frequency in acceptance speeches\n",
    "# query = \"\"\"\n",
    "# SELECT cleaned_speech FROM speeches;\n",
    "# \"\"\"\n",
    "# speech_texts = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Analysis (examples)\n",
    "- In this analysis, we explored the relationship between the race of law enforcement officers and the race of the drivers they stop. Our goal was to see if there‚Äôs any indication of bias in traffic stops based on the racial identity of the officers. To do this, we used a chi-squared test for independence, which helps us understand whether there‚Äôs a meaningful connection between these two groups.\n",
    "\n",
    "### Results of the Chi-Squared Test\n",
    "- **Chi-Squared Statistic:** We calculated a chi-squared statistic of 122.92. This high number shows that there‚Äôs a significant difference between the actual number of stops for different racial groups and what we would expect to see if there were no connection between the officer's race and the driver's race. In other words, this suggests that the patterns we observe in the data are unlikely to be just a coincidence.\n",
    "\n",
    "- **P-Value:** The p-value we found was about 8.20e-17, which is extremely low. This tells us that the result is statistically significant since it‚Äôs much lower than the usual thresholds (like 0.05 or 0.01). A low p-value means we have strong evidence against the idea that there‚Äôs no connection between the officer's race and the driver's race.\n",
    "\n",
    "### Interpretation of Findings\n",
    "- The results show a strong connection between the race of the officer and the race of the driver being stopped. This means that a driver's chances of being stopped may change depending on the officer's race, suggesting there might be some bias in how traffic stops are carried out.\n",
    "\n",
    "### Implications\n",
    "- These findings are important for understanding how race plays a role in law enforcement. They suggest that different racial groups might be treated differently by officers during traffic stops. It's crucial to address these biases to ensure fairness and equality in policing.\n",
    "\n",
    "### Conclusion\n",
    "- The strong evidence from the chi-squared statistic and p-value emphasizes the importance of further examining law enforcement practices. Police leaders and community advocacy groups should take these findings into account when reviewing policies and training programs designed to reduce racial bias in policing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
