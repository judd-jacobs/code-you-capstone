{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academy Awards Analysis üé¨\n",
    "## Investigating Trends in Oscar-Winning Movies\n",
    "### Author: Judd Jacobs\n",
    "\n",
    "This project analyzes historical **Academy Award-winning films** using data from **Wikipedia**, **The Movie Database (TMDb)**, and **The Open Movie Database (OMDb)**.\n",
    "\n",
    "## **Key Analysis Areas**\n",
    "- **Best Picture trends by genre** (from Wikipedia Scrape & TMDb API) üèÜ\n",
    "- **Box office revenue & IMDb ratings** (OMDb API) üé≠\n",
    "- **Long-term trends in Oscar-winning films** üìà"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1:** Import necessary Python Libraries üíΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import json\n",
    "from sqlalchemy import create_engine, text\n",
    "from difflib import get_close_matches\n",
    "import time\n",
    "\n",
    "# # WordCloud and NLTK libraries are currently a strech goal for future development\n",
    "# from wordcloud import WordCloud\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# # Ensure necessary NLTK components are downloaded\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2:** Data Acquisition üóÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì• 2.0: Scrape and Prepare Best Picture Data from Wikipedia\n",
    "\n",
    "This step scrapes the [Wikipedia page for Academy Award‚Äìwinning films](https://en.wikipedia.org/wiki/List_of_Academy_Award%E2%80%93winning_films) to extract and clean a table of Best Picture nominees and winners. The scraping process uses a **combined approach**:\n",
    "\n",
    "- **`BeautifulSoup`** parses the HTML to identify which films were marked as *winners* (based on a gold background highlight in the table rows).\n",
    "- **`pandas`** is used to structure and clean the tabular data.\n",
    "\n",
    "Key features of this data ingestion and cleaning step include:\n",
    "\n",
    "- üèÜ **Status Classification**: Each film is classified as either `\"Winner\"` or `\"Nominee\"` based on HTML styling.\n",
    "- üßπ **Data Normalization**: Column names are converted to lowercase `snake_case` for consistency and SQL compatibility.\n",
    "- üî¢ **Type Conversion**: `year`, `awards`, and `nominations` columns are explicitly converted to numeric types, using nullable `Int64` where applicable.\n",
    "- ‚úÖ **Data Validation**: Built-in `assert` statements confirm that:\n",
    "  - All expected columns are present.\n",
    "  - The `film` and `year` values are not missing.\n",
    "  - Only valid status values (`Winner`, `Nominee`) are included.\n",
    "  - The `year` column is stored as an integer type.\n",
    "\n",
    "This will produce a structured and validated DataFrame (`best_picture_wikipedia`) ready for storage in a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             film  year  awards  nominations   status\n",
      "0           Anora  2024       5            6   Winner\n",
      "1   The Brutalist  2024       3           10  Nominee\n",
      "2    Emilia P√©rez  2024       2           13  Nominee\n",
      "3          Wicked  2024       2           10  Nominee\n",
      "4  Dune: Part Two  2024       2            5  Nominee\n",
      "film           object\n",
      "year            Int64\n",
      "awards          Int64\n",
      "nominations     Int64\n",
      "status         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 2.1: Fetch Wikipedia page and parse it with BeautifulSoup\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_Academy_Award%E2%80%93winning_films\"\n",
    "response = requests.get(wiki_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 2.2: Locate the table and rows\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "# 2.3: Extract column headers\n",
    "headers = [th.get_text(strip=True) for th in rows[0].find_all(\"th\")]\n",
    "\n",
    "# 2.4: Extract table data and append 'Status' based on style\n",
    "data = []\n",
    "for row in rows[1:]:\n",
    "    cells = row.find_all([\"td\", \"th\"])\n",
    "    style = row.get(\"style\", \"\")\n",
    "    status = \"Winner\" if \"background:#EEDD82\" in style.replace(\" \", \"\") else \"Nominee\"\n",
    "    row_data = [cell.get_text(strip=True) for cell in cells]\n",
    "    if row_data:\n",
    "        row_data.append(status)\n",
    "        data.append(row_data)\n",
    "\n",
    "# 2.5: Append 'Status' to column headers\n",
    "headers.append(\"Status\")\n",
    "\n",
    "# 2.6: Create initial DataFrame\n",
    "best_picture_wikipedia = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# 2.7: Normalize column names\n",
    "best_picture_wikipedia.columns = (\n",
    "    best_picture_wikipedia.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(r\"[^\\w_]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "# 2.8: Initial conversion of 'year' to numeric\n",
    "best_picture_wikipedia['year'] = pd.to_numeric(best_picture_wikipedia['year'], errors='coerce')\n",
    "\n",
    "# 2.9: Further clean numeric columns\n",
    "for col in ['awards', 'nominations']:\n",
    "    if col in best_picture_wikipedia.columns:\n",
    "        best_picture_wikipedia[col] = (\n",
    "            best_picture_wikipedia[col]\n",
    "            .str.replace(\",\", \"\")\n",
    "            .str.extract(\"(\\\\d+)\")\n",
    "            .astype(float)\n",
    "            .astype(\"Int64\")\n",
    "        )\n",
    "\n",
    "# 2.10: Convert year to integer (nullable)\n",
    "best_picture_wikipedia['year'] = best_picture_wikipedia['year'].astype(\"Int64\")\n",
    "\n",
    "# 2.11: Validate data integrity\n",
    "expected_columns = ['film', 'year', 'awards', 'nominations', 'status']\n",
    "assert all(col in best_picture_wikipedia.columns for col in expected_columns), \"Missing expected columns\"\n",
    "assert best_picture_wikipedia['film'].notna().all(), \"Null values found in 'film'\"\n",
    "assert best_picture_wikipedia['year'].notna().any(), \"No valid 'year' entries found\"\n",
    "assert set(best_picture_wikipedia['status'].unique()) <= {'Winner', 'Nominee'}, \"Unexpected status values\"\n",
    "assert pd.api.types.is_integer_dtype(best_picture_wikipedia['year']), \"'year' column is not integer\"\n",
    "\n",
    "# 2.12: Preview final cleaned DataFrame\n",
    "print(best_picture_wikipedia.head())\n",
    "print(best_picture_wikipedia.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Save Cleaned DataFrame to SQLite\n",
    "\n",
    "Store the cleaned and validated `best_picture_wikipedia` DataFrame into a local SQLite database file (`academy_awards.db`) using the table name `oscars_wikipedia`.\n",
    "\n",
    "Key features of this database integration process:\n",
    "\n",
    "- üß± **Explicit Schema Definition**: The database table is created with clear column types, constraints, and a composite primary key on (`film`, `year`) to prevent duplicates.\n",
    "- üîê **Data Integrity**: The `status` field is constrained to only accept `Winner` or `Nominee` values.\n",
    "- üîÅ **Flexible Insert Mode**: The `to_sql()` method uses the `replace` mode to overwrite any existing data, ensuring the database stays synced with the cleaned DataFrame.\n",
    "- ‚úÖ **Post-insert Verification**: A row count query is executed after the insert to confirm that the operation succeeded.\n",
    "\n",
    "This will set up the foundation for future querying, enrichment, and analysis within a structured relational database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully inserted 1387 rows into 'oscars_wikipedia' table.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import sqlite3\n",
    "\n",
    "# 2.13: Define the path to your database\n",
    "database_path = \"academy_awards.db\"\n",
    "table_name = \"oscars_wikipedia\"\n",
    "\n",
    "# 2.14: Create engine\n",
    "engine = create_engine(f\"sqlite:///{database_path}\")\n",
    "\n",
    "# 2.15: Define schema with raw SQL (only if creating manually; optional step)\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            film TEXT NOT NULL,\n",
    "            year INTEGER NOT NULL,\n",
    "            awards INTEGER,\n",
    "            nominations INTEGER,\n",
    "            status TEXT CHECK(status IN ('Winner', 'Nominee')),\n",
    "            PRIMARY KEY (film, year)\n",
    "        );\n",
    "    \"\"\"))\n",
    "\n",
    "# 2.16: Insert data from DataFrame (will append or replace if desired)\n",
    "best_picture_wikipedia.to_sql(\n",
    "    name=table_name,\n",
    "    con=engine,\n",
    "    if_exists=\"replace\",  # options: 'fail', 'replace', 'append'\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# 2.17: Confirm insertion\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "    total_rows = result.scalar()\n",
    "    print(f\"‚úÖ Successfully inserted {total_rows} rows into '{table_name}' table.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé≠ Fetch & Normalize Movie Genres from TMDb API\n",
    "\n",
    "This cell enriches the Wikipedia-based Best Picture dataset by using **The Movie Database (TMDb) API** to retrieve detailed **genre information** for each film. It improves match accuracy, ensures data integrity, and produces a clean long-format DataFrame that is suitable for further analysis and storage.\n",
    "\n",
    "**Key steps and improvements:**\n",
    "\n",
    "- üîç **Fuzzy Matching Support**: If TMDb does not return an exact match for a film title, the function tries to find a close match using `difflib.get_close_matches()`.\n",
    "- üß≠ **Year Disambiguation**: Each search includes the film's release year to better filter results.\n",
    "- ‚è±Ô∏è **Rate Limiting**: A 250ms pause between requests ensures compliance with TMDb's API rate limits.\n",
    "- üßπ **Genre Normalization**: Each genre is flattened into its own row (one movie ‚Üí many genres).\n",
    "- üõë **Error Logging**: Titles with no valid match are skipped and logged separately for future review.\n",
    "- ‚úÖ **De-duplication**: The final genre list is cleaned of redundant rows using `.drop_duplicates()`.\n",
    "\n",
    "This output will be useful for identifying genre trends across decades, constructing visualizations, and enriching the SQLite database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            film  year    genre\n",
      "0          Anora  2024    Drama\n",
      "1          Anora  2024   Comedy\n",
      "2          Anora  2024  Romance\n",
      "3  The Brutalist  2024    Drama\n",
      "4   Emilia P√©rez  2024    Drama\n",
      "film     object\n",
      "year      Int64\n",
      "genre    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the TMDB API keys stored in the .env file\n",
    "tmdb_api_key = os.getenv('TMDB_API_KEY')\n",
    "tmdb_api_read_access_token = os.getenv('TMDB_API_READ_ACCESS_TOKEN')\n",
    "\n",
    "tmdb_api_base_url = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "# Function to get genre mappings (ID -> Name)\n",
    "def get_genre_mapping() -> dict:\n",
    "    url = f\"{tmdb_api_base_url}/genre/movie/list?language=en-US\"\n",
    "    headers = {\"accept\": \"application/json\", \"Authorization\": f\"Bearer {tmdb_api_read_access_token}\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    if \"genres\" in data:\n",
    "        return {genre[\"id\"]: genre[\"name\"] for genre in data[\"genres\"]}\n",
    "    return {}\n",
    "\n",
    "# Function to query TMDB API and get genre names for movies\n",
    "def get_movie_genres(films_df) -> pd.DataFrame:\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {tmdb_api_read_access_token}\"\n",
    "    }\n",
    "\n",
    "    genre_mapping = get_genre_mapping()\n",
    "    genre_rows = []\n",
    "    errors = []\n",
    "\n",
    "    for _, row in films_df.iterrows():\n",
    "        title = row['film']\n",
    "        year = row['year']\n",
    "        encoded_title = quote(title)\n",
    "\n",
    "        url = f\"{tmdb_api_base_url}/search/movie?query={encoded_title}&include_adult=false&language=en-US&page=1&primary_release_year={year}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "\n",
    "        # Rate limiting\n",
    "        time.sleep(0.25)\n",
    "\n",
    "        genres = []\n",
    "        match_title = None\n",
    "\n",
    "        if \"results\" in data and data[\"results\"]:\n",
    "            exact_match = next((movie for movie in data[\"results\"] if movie[\"title\"].lower().strip() == title.lower().strip()), None)\n",
    "\n",
    "            if not exact_match:\n",
    "                # Try fuzzy matching if no exact match found\n",
    "                titles = [movie[\"title\"] for movie in data[\"results\"]]\n",
    "                close_matches = get_close_matches(title, titles, n=1, cutoff=0.8)\n",
    "                if close_matches:\n",
    "                    match_title = close_matches[0]\n",
    "                    exact_match = next((movie for movie in data[\"results\"] if movie[\"title\"] == match_title), None)\n",
    "\n",
    "            if exact_match:\n",
    "                genre_ids = exact_match.get(\"genre_ids\", [])\n",
    "                genres = [genre_mapping.get(gid, \"Unknown Genre\") for gid in genre_ids]\n",
    "\n",
    "        if not genres:\n",
    "            errors.append({\"film\": title, \"year\": year})\n",
    "            continue\n",
    "\n",
    "        for genre in genres:\n",
    "            genre_rows.append({\"film\": title, \"year\": year, \"genre\": genre})\n",
    "\n",
    "    genre_df = pd.DataFrame(genre_rows).drop_duplicates()\n",
    "    return genre_df\n",
    "\n",
    "# Generate genre dataframe using film titles and years\n",
    "tmdb_genre_results = get_movie_genres(best_picture_wikipedia[[\"film\", \"year\"]])\n",
    "\n",
    "# Ensure proper data types\n",
    "tmdb_genre_results['year'] = pd.to_numeric(tmdb_genre_results['year'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Display sample and data types\n",
    "print(tmdb_genre_results.head())\n",
    "print(tmdb_genre_results.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Save TMDb Genre Data to SQLite Database\n",
    "\n",
    "This cell saves the normalized genre data (`tmdb_genre_results`) into the SQLite database (`academy_awards.db`) using a new table called `movie_genres`. Each row in this table represents a single genre assigned to a film for a given year.\n",
    "\n",
    "Key features of this database export step:\n",
    "\n",
    "- ‚úÖ Saves data in long format for clean relational use\n",
    "- üß© Table includes `film`, `year`, and `genre` columns\n",
    "- üîê Primary key constraint ensures uniqueness by film, year, and genre\n",
    "- ‚ôªÔ∏è Existing table (if present) will be replaced with fresh data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully inserted 2731 rows into 'movie_genres' table.\n"
     ]
    }
   ],
   "source": [
    "# Define database path and table name\n",
    "database_path = \"academy_awards.db\"\n",
    "table_name = \"movie_genres\"\n",
    "\n",
    "# Create engine for database connection\n",
    "engine = create_engine(f\"sqlite:///{database_path}\")\n",
    "\n",
    "# Define schema and create table if not exists\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            film TEXT NOT NULL,\n",
    "            year INTEGER NOT NULL,\n",
    "            genre TEXT NOT NULL,\n",
    "            PRIMARY KEY (film, year, genre)\n",
    "        );\n",
    "    \"\"\"))\n",
    "\n",
    "# Write data to SQLite (replace if exists)\n",
    "tmdb_genre_results.to_sql(\n",
    "    name=table_name,\n",
    "    con=engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Confirm insertion\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "    total_rows = result.scalar()\n",
    "    print(f\"‚úÖ Successfully inserted {total_rows} rows into '{table_name}' table.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé¨ Fetch Movie Metadata from OMDb API\n",
    "\n",
    "This cell uses the **OMDb API** to enrich the Best Picture dataset with additional movie metadata such as:\n",
    "\n",
    "- üí∞ Box office revenue\n",
    "- ‚è±Ô∏è Runtime\n",
    "- ‚≠ê IMDb rating and Metascore\n",
    "- üìù Plot summary\n",
    "- üåê Language and Country\n",
    "\n",
    "Each record is matched using the film title and year. To improve performance and avoid redundant API calls, results are **cached locally in a `.json` file**. On subsequent runs, only uncached titles will be queried from the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OMDb API key from environment\n",
    "omdb_api_key = os.getenv(\"OMDB_API_KEY\")\n",
    "\n",
    "# Base URL for OMDb API\n",
    "omdb_api_url = \"http://www.omdbapi.com/\"\n",
    "\n",
    "# Load existing cache if available\n",
    "import os.path\n",
    "cache_file = \"omdb_cache.json\"\n",
    "if os.path.exists(cache_file):\n",
    "    omdb_cache = pd.read_json(cache_file)\n",
    "else:\n",
    "    omdb_cache = pd.DataFrame()\n",
    "\n",
    "# Function to fetch metadata for a list of films\n",
    "def get_omdb_metadata(films, existing_cache) -> pd.DataFrame:\n",
    "    records = []\n",
    "    errors = []\n",
    "    seen_keys = set(zip(existing_cache['film'], existing_cache['year'])) if not existing_cache.empty else set()\n",
    "\n",
    "    for _, row in films.iterrows():\n",
    "        title = row['film']\n",
    "        year = row['year']\n",
    "\n",
    "        if (title, year) in seen_keys:\n",
    "            continue  # skip already cached\n",
    "\n",
    "        params = {\n",
    "            \"t\": title,\n",
    "            \"y\": year,\n",
    "            \"apikey\": omdb_api_key\n",
    "        }\n",
    "\n",
    "        response = requests.get(omdb_api_url, params=params)\n",
    "        print(f\"URL: {response.url} | Status: {response.status_code} | Text: {response.text[:200]}\")\n",
    "        try:\n",
    "            data = response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to parse JSON for: {title} ({year}) ‚Äî {e}\")\n",
    "            errors.append({\"film\": title, \"year\": year, \"error\": \"Invalid JSON\"})\n",
    "            continue\n",
    "\n",
    "        if data.get(\"Response\") == \"True\":\n",
    "            records.append({\n",
    "                \"film\": title,\n",
    "                \"year\": year,\n",
    "                \"title_api\": data.get(\"Title\"),\n",
    "                \"rated\": data.get(\"Rated\"),\n",
    "                \"released\": data.get(\"Released\"),\n",
    "                \"runtime\": data.get(\"Runtime\"),\n",
    "                \"genre\": data.get(\"Genre\"),\n",
    "                \"director\": data.get(\"Director\"),\n",
    "                \"writer\": data.get(\"Writer\"),\n",
    "                \"actors\": data.get(\"Actors\"),\n",
    "                \"plot\": data.get(\"Plot\"),\n",
    "                \"language\": data.get(\"Language\"),\n",
    "                \"country\": data.get(\"Country\"),\n",
    "                \"awards\": data.get(\"Awards\"),\n",
    "                \"poster\": data.get(\"Poster\"),\n",
    "                \"ratings\": data.get(\"Ratings\"),\n",
    "                \"metascore\": data.get(\"Metascore\"),\n",
    "                \"imdbRating\": data.get(\"imdbRating\"),\n",
    "                \"imdbVotes\": data.get(\"imdbVotes\"),\n",
    "                \"imdbID\": data.get(\"imdbID\"),\n",
    "                \"type\": data.get(\"Type\"),\n",
    "                \"boxOffice\": data.get(\"BoxOffice\"),\n",
    "                \"response\": data.get(\"Response\")\n",
    "            })\n",
    "        else:\n",
    "            errors.append({\"film\": title, \"year\": year, \"error\": data.get(\"Error\")})\n",
    "\n",
    "    return pd.DataFrame(records), pd.DataFrame(errors)\n",
    "\n",
    "# Run the metadata fetch, combining with cache\n",
    "new_records, omdb_errors = get_omdb_metadata(best_picture_wikipedia[[\"film\", \"year\"]], omdb_cache)\n",
    "omdb_metadata = pd.concat([omdb_cache, new_records], ignore_index=True).drop_duplicates(subset=[\"film\", \"year\"])\n",
    "\n",
    "# Save updated cache\n",
    "omdb_metadata.to_json(cache_file, orient=\"records\", indent=2)\n",
    "\n",
    "# Preview the results\n",
    "print(omdb_metadata.head())\n",
    "\n",
    "# Convert and clean data types for key fields\n",
    "omdb_metadata['runtime_mins'] = omdb_metadata['runtime'].str.extract(r'(\\d+)').astype('Int64')\n",
    "\n",
    "omdb_metadata['boxOffice_clean'] = pd.to_numeric(\n",
    "    omdb_metadata['boxOffice']\n",
    "    .astype(str)\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\")\n",
    "    .replace([\"N/A\", \"nan\"], pd.NA),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "omdb_metadata['metascore'] = pd.to_numeric(omdb_metadata['metascore'], errors='coerce')\n",
    "omdb_metadata['imdbRating'] = pd.to_numeric(omdb_metadata['imdbRating'], errors='coerce')\n",
    "\n",
    "omdb_metadata['imdbVotes'] = (\n",
    "    omdb_metadata['imdbVotes']\n",
    "    .str.replace(\",\", \"\")\n",
    "    .replace(\"N/A\", pd.NA)\n",
    "    .astype('Int64')\n",
    ")\n",
    "\n",
    "print(omdb_metadata.dtypes)\n",
    "\n",
    "# Summary of unmatched or errored entries\n",
    "if not omdb_errors.empty:\n",
    "    print(f\"\\n‚ö†Ô∏è {len(omdb_errors)} movies could not be matched or returned errors.\")\n",
    "    print(omdb_errors.sort_values(by=\"year\", ascending=False).reset_index(drop=True))\n",
    "else:\n",
    "    print(\"\\n‚úÖ All movies successfully matched in OMDb.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "film",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "error",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5e5d8b60-38f2-4c3f-8574-105edfeb53c0",
       "rows": [
        [
         "0",
         "I'm Not a Robot",
         "2024",
         "Movie not found!"
        ],
        [
         "1",
         "In the Shadow of the Cypress",
         "2024",
         "Movie not found!"
        ],
        [
         "2",
         "The Only Girl in the Orchestra",
         "2024",
         "Movie not found!"
        ],
        [
         "3",
         "War Is Over! Inspired by the Music of John and Yoko",
         "2023",
         "Movie not found!"
        ],
        [
         "4",
         "Nomadland",
         null,
         "Invalid JSON"
        ],
        [
         "5",
         "The Father",
         null,
         "Invalid JSON"
        ],
        [
         "6",
         "Judas and the Black Messiah",
         null,
         "Invalid JSON"
        ],
        [
         "7",
         "Minari",
         null,
         "Invalid JSON"
        ],
        [
         "8",
         "Mank",
         null,
         "Invalid JSON"
        ],
        [
         "9",
         "Sound of Metal",
         null,
         "Invalid JSON"
        ],
        [
         "10",
         "Ma Rainey's Black Bottom",
         null,
         "Invalid JSON"
        ],
        [
         "11",
         "Promising Young Woman",
         null,
         "Invalid JSON"
        ],
        [
         "12",
         "Tenet",
         null,
         "Invalid JSON"
        ],
        [
         "13",
         "Soul",
         null,
         "Invalid JSON"
        ],
        [
         "14",
         "Another Round",
         null,
         "Invalid JSON"
        ],
        [
         "15",
         "My Octopus Teacher",
         null,
         "Invalid JSON"
        ],
        [
         "16",
         "Colette",
         null,
         "Invalid JSON"
        ],
        [
         "17",
         "If Anything Happens I Love You",
         null,
         "Invalid JSON"
        ],
        [
         "18",
         "Two Distant Strangers",
         null,
         "Invalid JSON"
        ],
        [
         "19",
         "Heaven Is a Traffic Jam on the 405",
         "2017",
         "Movie not found!"
        ],
        [
         "20",
         "Flesh and Sand(Carne y arena)",
         "2017",
         "Movie not found!"
        ],
        [
         "21",
         "Crisis Hotline: Veterans Press 1",
         "2014",
         "Movie not found!"
        ],
        [
         "22",
         "The Phone Call",
         "2014",
         "Movie not found!"
        ],
        [
         "23",
         "The Hurt Locker",
         "2009",
         "Movie not found!"
        ],
        [
         "24",
         "Music by Prudence",
         "2009",
         "Movie not found!"
        ],
        [
         "25",
         "La Maison en Petits Cubes",
         "2008",
         "Movie not found!"
        ],
        [
         "26",
         "Peter & the Wolf",
         "2007",
         "Movie not found!"
        ],
        [
         "27",
         "Le Mozart des pickpockets",
         "2007",
         "Movie not found!"
        ],
        [
         "28",
         "The Counterfeiters(Die F√§lscher)",
         "2007",
         "Movie not found!"
        ],
        [
         "29",
         "Pan's Labyrinth(El laberinto del fauno)",
         "2006",
         "Movie not found!"
        ],
        [
         "30",
         "The Lives of Others(Das Leben der Anderen)",
         "2006",
         "Movie not found!"
        ],
        [
         "31",
         "West Bank Story",
         "2006",
         "Movie not found!"
        ],
        [
         "32",
         "March of the Penguins(La Marche de l'empereur)",
         "2005",
         "Movie not found!"
        ],
        [
         "33",
         "Six Shooter",
         "2005",
         "Movie not found!"
        ],
        [
         "34",
         "Lemony Snicket's A Series of Unfortunate Events",
         "2004",
         "Movie not found!"
        ],
        [
         "35",
         "Wasp",
         "2004",
         "Movie not found!"
        ],
        [
         "36",
         "Talk to Her(Hable con ella)",
         "2002",
         "Movie not found!"
        ],
        [
         "37",
         "This Charming Man(Der Er En Yndig Mand)",
         "2002",
         "Movie not found!"
        ],
        [
         "38",
         "Spirited Away",
         "2002",
         "Movie not found!"
        ],
        [
         "39",
         "Nowhere in Africa(Nirgendwo in Afrika)",
         "2002",
         "Movie not found!"
        ],
        [
         "40",
         "Thoth",
         "2001",
         "Movie not found!"
        ],
        [
         "41",
         "Murder on a Sunday Morning(Un coupable id√©al)",
         "2001",
         "Movie not found!"
        ],
        [
         "42",
         "The Red Violin(Le violon rouge)",
         "1999",
         "Movie not found!"
        ],
        [
         "43",
         "My Mother Dreams the Satan's Disciples in New York",
         "1999",
         "Movie not found!"
        ],
        [
         "44",
         "All About My Mother(Todo sobre mi madre)",
         "1999",
         "Movie not found!"
        ],
        [
         "45",
         "Life Is Beautiful(La vita √® bella)",
         "1998",
         "Movie not found!"
        ],
        [
         "46",
         "Affliction",
         "1998",
         "Movie not found!"
        ],
        [
         "47",
         "Election Night(Valgaften)",
         "1998",
         "Movie not found!"
        ],
        [
         "48",
         "Character(Karakter)",
         "1997",
         "Movie not found!"
        ],
        [
         "49",
         "Il Postino: The Postman",
         "1995",
         "Movie not found!"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 247
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>year</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm Not a Robot</td>\n",
       "      <td>2024</td>\n",
       "      <td>Movie not found!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the Shadow of the Cypress</td>\n",
       "      <td>2024</td>\n",
       "      <td>Movie not found!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Only Girl in the Orchestra</td>\n",
       "      <td>2024</td>\n",
       "      <td>Movie not found!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>War Is Over! Inspired by the Music of John and...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Movie not found!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nomadland</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Invalid JSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>With Byrd at the South Pole</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Invalid JSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>World Without Sun(Le Monde sans soleil)</td>\n",
       "      <td>1964</td>\n",
       "      <td>Movie not found!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Wrestling Swordfish</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Invalid JSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Yesterday, Today and Tomorrow(Ieri, oggi, domani)</td>\n",
       "      <td>1964</td>\n",
       "      <td>Movie not found!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Zorba the Greek(Alexis Zorbas)</td>\n",
       "      <td>1964</td>\n",
       "      <td>Movie not found!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  film  year             error\n",
       "0                                      I'm Not a Robot  2024  Movie not found!\n",
       "1                         In the Shadow of the Cypress  2024  Movie not found!\n",
       "2                       The Only Girl in the Orchestra  2024  Movie not found!\n",
       "3    War Is Over! Inspired by the Music of John and...  2023  Movie not found!\n",
       "4                                            Nomadland  <NA>      Invalid JSON\n",
       "..                                                 ...   ...               ...\n",
       "242                        With Byrd at the South Pole  <NA>      Invalid JSON\n",
       "243            World Without Sun(Le Monde sans soleil)  1964  Movie not found!\n",
       "244                                Wrestling Swordfish  <NA>      Invalid JSON\n",
       "245  Yesterday, Today and Tomorrow(Ieri, oggi, domani)  1964  Movie not found!\n",
       "246                     Zorba the Greek(Alexis Zorbas)  1964  Movie not found!\n",
       "\n",
       "[247 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omdb_errors.sort_values(by=\"year\", ascending=False).reset_index(drop=True)\n",
    "omdb_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Save OMDb Metadata to SQLite Database\n",
    "\n",
    "This cell saves the cleaned and enriched OMDb metadata stored in the `omdb_metadata` DataFrame to a SQLite database (`academy_awards.db`).\n",
    "\n",
    "Key features of this step:\n",
    "- Stores full movie metadata from the OMDb API\n",
    "- Uses a structured schema with a composite primary key on (`film`, `year`)\n",
    "- Automatically replaces existing data in the table `omdb_metadata` for easy refresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully inserted 1140 rows into 'omdb_metadata' table.\n"
     ]
    }
   ],
   "source": [
    "# Define database path and table name\n",
    "database_path = \"academy_awards.db\"\n",
    "table_name = \"omdb_metadata\"\n",
    "engine = create_engine(f\"sqlite:///{database_path}\")\n",
    "\n",
    "# Define table schema and create if not exists\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            film TEXT NOT NULL,\n",
    "            year INTEGER NOT NULL,\n",
    "            title_api TEXT,\n",
    "            rated TEXT,\n",
    "            released TEXT,\n",
    "            runtime TEXT,\n",
    "            genre TEXT,\n",
    "            director TEXT,\n",
    "            writer TEXT,\n",
    "            actors TEXT,\n",
    "            plot TEXT,\n",
    "            language TEXT,\n",
    "            country TEXT,\n",
    "            awards TEXT,\n",
    "            poster TEXT,\n",
    "            ratings TEXT,\n",
    "            metascore REAL,\n",
    "            imdbRating REAL,\n",
    "            imdbVotes INTEGER,\n",
    "            imdbID TEXT,\n",
    "            type TEXT,\n",
    "            boxOffice TEXT,\n",
    "            response TEXT,\n",
    "            runtime_mins INTEGER,\n",
    "            boxOffice_clean REAL,\n",
    "            PRIMARY KEY (film, year)\n",
    "        );\n",
    "    \"\"\"))\n",
    "\n",
    "# Convert lists to strings for SQLite compatibility\n",
    "omdb_metadata[\"ratings\"] = omdb_metadata[\"ratings\"].astype(str)\n",
    "\n",
    "# Write data to SQLite (replace if exists)\n",
    "table_inserted = omdb_metadata.to_sql(\n",
    "    name=table_name,\n",
    "    con=engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Confirm insertion\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(f\"SELECT COUNT(*) FROM {table_name}\"))\n",
    "    row_count = result.scalar()\n",
    "    print(f\"‚úÖ Successfully inserted {row_count} rows into '{table_name}' table.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm column names for both DataFrames\n",
    "print(\"best_picture_wikipedia columns:\", best_picture_wikipedia.columns.tolist())\n",
    "print(\"tmdb_genre_results columns:\", tmdb_genre_results.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge best_picture_wikipedia and tmdb_genre_results DataFrames on \"Film\"/\"Title\"\n",
    "best_picture_merged = best_picture_wikipedia.merge(\n",
    "    tmdb_genre_results,\n",
    "    left_on=\"Film\",\n",
    "    right_on=\"Title\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Drop the now redundant \"Title\" column\n",
    "best_picture_merged.drop(\"Title\", axis=1, inplace=True)\n",
    "\n",
    "# Split the genres into separate columns\n",
    "best_picture_merged = best_picture_merged.explode(\"Genres\")\n",
    "best_picture_merged = pd.concat([best_picture_merged, best_picture_merged[\"Genres\"].str.get_dummies()], axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(best_picture_merged.head())\n",
    "print(best_picture_merged.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3:** Data Cleaning & Storage üõ†\n",
    "Merged data will have some cleaning applied and then the cleaned dataset will be stored in a local **SQLite database**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_money(val) -> float:\n",
    "    \"\"\"Function to clean money values stored as strings\"\"\"\n",
    "    if pd.isna(val) or val == \"N/A\":\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(str(val).replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def clean_votes(val) -> float:\n",
    "    \"\"\"Function to clean vote counts stored as strings\"\"\"\n",
    "    if pd.isna(val) or val == \"N/A\":\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(str(val).replace(\",\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def clean_runtime(runtime_str) -> int:\n",
    "    \"\"\"Function to clean runtime values stored as strings\"\"\"\n",
    "    if pd.isna(runtime_str) or runtime_str == \"N/A\":\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(str(runtime_str).split()[0])\n",
    "    except (ValueError, IndexError):\n",
    "        return np.nan\n",
    "\n",
    "# Make a copy of the merged raw dataset to avoid mutating the original\n",
    "best_picture_all_clean = best_picture_all.copy()\n",
    "\n",
    "# Filter rows based on columns: 'Response', 'Type'\n",
    "best_picture_all_clean = best_picture_all_clean[(best_picture_all_clean['Response'].str.contains(\"True\", regex=False, na=False, case=False))\n",
    "                                                 & (best_picture_all['Type'].str.contains(\"movie\", regex=False, na=False, case=False))]\n",
    "\n",
    "# Drop unnecessary or empty columns\n",
    "best_picture_all_clean.drop(columns=[\"Website\", \"DVD\", \"Production\"], inplace=True, errors='ignore')\n",
    "\n",
    "# Execute the cleaning functions\n",
    "best_picture_all_clean[\"BoxOffice\"] = best_picture_all_clean[\"BoxOffice\"].apply(clean_money)\n",
    "\n",
    "# Apply to imdbVotes only (since it's a string with commas)\n",
    "best_picture_all_clean[\"imdbVotes\"] = best_picture_all_clean[\"imdbVotes\"].apply(clean_votes)\n",
    "\n",
    "# Apply to Runtime column\n",
    "best_picture_all_clean[\"Runtime\"] = best_picture_all_clean[\"Runtime\"].apply(clean_runtime)\n",
    "\n",
    "# Conversion for numeric columns stored as text\n",
    "numeric_columns = [\"imdbRating\", \"Metascore\"]\n",
    "best_picture_all_clean[numeric_columns] = best_picture_all_clean[numeric_columns].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Rename the column\n",
    "best_picture_all_clean.rename(columns={\"Runtime\": \"Runtime (mins)\"}, inplace=True)\n",
    "\n",
    "# Convert \"N/A\" to NaN across object columns\n",
    "best_picture_all_clean.replace(\"N/A\", np.nan, inplace=True)\n",
    "\n",
    "# Convert Year to integer\n",
    "best_picture_all_clean[\"Year\"] = pd.to_numeric(best_picture_all_clean[\"Year\"], errors=\"coerce\")\n",
    "\n",
    "# Preview cleaned DataFrame\n",
    "best_picture_all_clean.info()\n",
    "best_picture_all_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cleaned data to local SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicated movie metadata for movies table\n",
    "movies = best_picture_all_clean.drop_duplicates(subset=[\"Film\", \"Year\"]).copy()\n",
    "\n",
    "# 2. Normalize genre columns\n",
    "genre_columns = [\n",
    "    \"Action\", \"Adventure\", \"Animation\", \"Comedy\", \"Crime\", \"Documentary\",\n",
    "    \"Drama\", \"Family\", \"Fantasy\", \"History\", \"Horror\", \"Music\", \"Mystery\",\n",
    "    \"Romance\", \"Science Fiction\", \"TV Movie\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "genre = best_picture_all_clean[[\"Film\", \"Year\"] + genre_columns].melt(\n",
    "    id_vars=[\"Film\", \"Year\"],\n",
    "    value_vars=genre_columns,\n",
    "    var_name=\"Genre\",\n",
    "    value_name=\"IsPresent\"\n",
    ")\n",
    "\n",
    "# Keep only rows where genre is present\n",
    "movie_genres = genre[genre[\"IsPresent\"] == 1].drop(columns=\"IsPresent\")\n",
    "\n",
    "# 3. Store both in SQLite\n",
    "with sqlite3.connect(\"academy_awards.db\") as conn:\n",
    "    movies.to_sql(\"movies\", conn, if_exists=\"replace\", index=False)\n",
    "    movie_genres.to_sql(\"movie_genres\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"Data successfully split and stored in SQLite!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis üìä\n",
    "We will explore trends in **Best Picture winners** by genre and other relevant statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "with sqlite3.connect(\"academy_awards.db\") as conn:\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Query to list all table names\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    \n",
    "    # Fetch and print table names\n",
    "    tables = cursor.fetchall()\n",
    "    print(\"Tables in database:\")\n",
    "    for table in tables:\n",
    "        print(f\"- {table[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect and read the data\n",
    "with sqlite3.connect(\"academy_awards.db\") as conn:\n",
    "    movies = pd.read_sql(\"SELECT * FROM movies\", conn)\n",
    "    movie_genres = pd.read_sql(\"SELECT * FROM movie_genres\", conn)\n",
    "\n",
    "print(f\"Movies loaded: {len(movies)}\")\n",
    "print(f\"Genre rows loaded: {len(movie_genres)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Office Revenue vs Number of Nominations\n",
    "box_office_vs_nomination = movies.dropna(subset=[\"BoxOffice\", \"Nominations\"])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(box_office_vs_nomination[\"Nominations\"], box_office_vs_nomination[\"BoxOffice\"], alpha=0.6)\n",
    "plt.title(\"Box Office Revenue vs Number of Nominations\")\n",
    "plt.xlabel(\"Number of Nominations\")\n",
    "plt.ylabel(\"Box Office Revenue (USD)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Office Revenue vs IMDb Rating (Per Movie)\n",
    "box_office_vs_imdb_rating = movies.dropna(subset=[\"imdbRating\", \"BoxOffice\"])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(box_office_vs_imdb_rating[\"imdbRating\"], [\"BoxOffice\"], alpha=0.6)\n",
    "plt.title(\"Box Office Revenue vs IMDb Rating (Per Movie)\")\n",
    "plt.xlabel(\"IMDb Rating\")\n",
    "plt.ylabel(\"Box Office Revenue (USD)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ† SQL Queries for Data Exploration\n",
    "Now that our data is stored in SQLite, we will perform **SQL queries** to explore trends:\n",
    "- **Most Awarded Films**\n",
    "- **Box Office Performance (Stretch Goal)**\n",
    "- **Decade-wise Genre Trends**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(\"academy_awards.db\")\n",
    "\n",
    "# Query: Top 10 Most Awarded Films\n",
    "query_awards = \"\"\"\n",
    "SELECT Film, `Awards Won`\n",
    "FROM academy_award_winners\n",
    "ORDER BY `Awards Won` DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# Execute query\n",
    "top_awarded_films = pd.read_sql(query_awards, conn)\n",
    "print(\"Top 10 Most Awarded Films:\")\n",
    "print(top_awarded_films)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualization: Top 10 Most Awarded Films\n",
    "We will create a **bar chart** to visualize the **most awarded films** in Academy Award history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bar Chart for Most Awarded Films\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(y=top_awarded_films[\"Film\"], x=top_awarded_films[\"Awards Won\"], palette=\"Blues_r\")\n",
    "plt.xlabel(\"Awards Won\")\n",
    "plt.ylabel(\"Film\")\n",
    "plt.title(\"Top 10 Most Awarded Films in Academy Award History\")\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí∞ SQL Query: Average Box Office Revenue by Genre (Stretch Goal)\n",
    "If box office revenue data is available, we will analyze which **genres** tend to perform better financially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Average Box Office Revenue by Genre\n",
    "query_revenue = \"\"\"\n",
    "SELECT Genre, AVG(CAST(REPLACE(`Box Office Revenue`, '$', '') AS FLOAT)) AS Avg_Revenue\n",
    "FROM academy_award_winners\n",
    "WHERE `Box Office Revenue` IS NOT NULL AND `Box Office Revenue` != 'N/A'\n",
    "GROUP BY Genre\n",
    "ORDER BY Avg_Revenue DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute query\n",
    "box_office_by_genre = pd.read_sql(query_revenue, conn)\n",
    "print(\"Average Box Office Revenue by Genre:\")\n",
    "print(box_office_by_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualization: Box Office Revenue vs. Awards Won\n",
    "We will create a **scatter plot** to visualize the relationship between **box office revenue and the number of awards won**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Box Office Revenue to numeric\n",
    "awards_df[\"Box Office Revenue\"] = (\n",
    "    awards_df[\"Box Office Revenue\"]\n",
    "    .str.replace(\"$\", \"\")\n",
    "    .str.replace(\",\", \"\")\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=awards_df[\"Box Office Revenue\"], y=awards_df[\"Awards Won\"], hue=awards_df[\"Genre\"], palette=\"coolwarm\", alpha=0.8)\n",
    "plt.xlabel(\"Box Office Revenue (in millions)\")\n",
    "plt.ylabel(\"Awards Won\")\n",
    "plt.title(\"Box Office Revenue vs. Awards Won\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÖ Visualization: Timeline of Best Picture Wins\n",
    "We will visualize how **Academy Award wins have changed over the decades** using a **line chart**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate awards by decade\n",
    "awards_df[\"Decade\"] = (awards_df[\"Year\"] // 10) * 10\n",
    "awards_by_decade = awards_df.groupby(\"Decade\")[\"Awards Won\"].sum().reset_index()\n",
    "\n",
    "# Line Plot for Award Wins Over Time\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=awards_by_decade[\"Decade\"], y=awards_by_decade[\"Awards Won\"], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.xlabel(\"Decade\")\n",
    "plt.ylabel(\"Total Awards Won\")\n",
    "plt.title(\"Best Picture Wins Over the Decades\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows to avoid double-counting movies\n",
    "movies_deduped = best_picture_all_clean.drop_duplicates(subset=[\"Film\", \"Year\"])\n",
    "print(f\"Original rows: {len(best_picture_all_clean)}, Deduplicated: {len(movies_deduped)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scatter_data = movies_deduped.dropna(subset=[\"imdbRating\", \"BoxOffice\"])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(scatter_data[\"imdbRating\"], scatter_data[\"BoxOffice\"], alpha=0.6)\n",
    "plt.title(\"Box Office Revenue vs IMDb Rating (Per Movie)\")\n",
    "plt.xlabel(\"IMDb Rating\")\n",
    "plt.ylabel(\"Box Office Revenue (USD)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of genre columns\n",
    "genre_columns = [\n",
    "    \"Action\", \"Adventure\", \"Animation\", \"Comedy\", \"Crime\", \"Documentary\",\n",
    "    \"Drama\", \"Family\", \"Fantasy\", \"History\", \"Horror\", \"Music\", \"Mystery\",\n",
    "    \"Romance\", \"Science Fiction\", \"TV Movie\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "# Group by year and sum genre counts\n",
    "genre_by_year = best_picture_all_clean.groupby(\"Year\")[genre_columns].sum().sort_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "genre_by_year.plot(kind=\"area\", stacked=True, alpha=0.85, figsize=(14, 7))\n",
    "plt.title(\"Genre Distribution of Best Picture Films Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Films (Genre-Normalized)\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by winner status\n",
    "winner_group = movies_deduped.groupby(\"Status\")[[\"imdbRating\", \"BoxOffice\"]].mean().dropna()\n",
    "\n",
    "# Plot\n",
    "winner_group.plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Average IMDb Rating and Box Office: Winner vs Nominee (Per Movie)\")\n",
    "plt.ylabel(\"Average Value\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows to avoid double-counting movies\n",
    "movies_deduped = best_picture_all_clean.drop_duplicates(subset=[\"Film\", \"Year\"])\n",
    "print(f\"Original rows: {len(best_picture_all_clean)}, Deduplicated: {len(movies_deduped)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scatter_data = movies_deduped.dropna(subset=[\"imdbRating\", \"BoxOffice\"])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(scatter_data[\"imdbRating\"], scatter_data[\"BoxOffice\"], alpha=0.6)\n",
    "plt.title(\"Box Office Revenue vs IMDb Rating (Per Movie)\")\n",
    "plt.xlabel(\"IMDb Rating\")\n",
    "plt.ylabel(\"Box Office Revenue (USD)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"box_office_vs_rating.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_columns = [\n",
    "    \"Action\", \"Adventure\", \"Animation\", \"Comedy\", \"Crime\", \"Documentary\",\n",
    "    \"Drama\", \"Family\", \"Fantasy\", \"History\", \"Horror\", \"Music\", \"Mystery\",\n",
    "    \"Romance\", \"Science Fiction\", \"TV Movie\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "genre_by_year = best_picture_all_clean.groupby(\"Year\")[genre_columns].sum().sort_index()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "genre_by_year.plot(kind=\"area\", stacked=True, alpha=0.85, figsize=(14, 7))\n",
    "plt.title(\"Genre Distribution of Best Picture Films Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Films (Genre-Normalized)\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"genre_distribution_over_time.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_group = movies_deduped.groupby(\"Status\")[[\"imdbRating\", \"BoxOffice\"]].mean().dropna()\n",
    "\n",
    "winner_group.plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Average IMDb Rating and Box Office: Winner vs Nominee (Per Movie)\")\n",
    "plt.ylabel(\"Average Value\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"winner_vs_nominee.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Unpivot genres for boxplot\n",
    "genre_ratings = best_picture_all_clean.melt(\n",
    "    id_vars=[\"imdbRating\"], value_vars=genre_columns,\n",
    "    var_name=\"Genre\", value_name=\"IsPresent\"\n",
    ")\n",
    "\n",
    "# Filter only rows where the genre is present\n",
    "genre_ratings = genre_ratings[genre_ratings[\"IsPresent\"] == 1]\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=genre_ratings, x=\"Genre\", y=\"imdbRating\")\n",
    "plt.title(\"IMDb Ratings by Genre (Genre-Normalized)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"genre_vs_rating_boxplot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = movies_deduped[movies_deduped[\"Status\"] == \"Winner\"].dropna(subset=[\"Year\", \"imdbRating\"])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(winners[\"Year\"], winners[\"imdbRating\"], marker=\"o\", linestyle=\"-\")\n",
    "plt.title(\"IMDb Rating of Best Picture Winners Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"IMDb Rating\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"winner_timeline.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre Distribution of Best Picture Films Over Time\n",
    "genre_pivot = movie_genres.assign(count=1).pivot_table(\n",
    "    index=\"Year\", columns=\"Genre\", values=\"count\", aggfunc=\"sum\", fill_value=0\n",
    ").sort_index()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "genre_pivot.plot(kind=\"area\", stacked=True, alpha=0.85, figsize=(14, 7))\n",
    "plt.title(\"Genre Distribution of Best Picture Films Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Films (Genre-Normalized)\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average IMDb Rating and Box Office: Winner vs Nominee (Per Movie)\n",
    "winner_group = movies.groupby(\"Status\")[[\"imdbRating\", \"BoxOffice\"]].mean().dropna()\n",
    "\n",
    "winner_group.plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Average IMDb Rating and Box Office: Winner vs Nominee (Per Movie)\")\n",
    "plt.ylabel(\"Average Value\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDb Ratings by Genre (Genre-Normalized)\n",
    "genre_ratings = movie_genres.merge(movies[[\"Film\", \"Year\", \"imdbRating\"]], on=[\"Film\", \"Year\"])\n",
    "genre_ratings = genre_ratings.dropna(subset=[\"imdbRating\"])\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=genre_ratings, x=\"Genre\", y=\"imdbRating\")\n",
    "plt.title(\"IMDb Ratings by Genre (Genre-Normalized)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDb Rating of Best Picture Winners Over Time\n",
    "winners = movies[movies[\"Status\"] == \"Winner\"].dropna(subset=[\"Year\", \"imdbRating\"])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(winners[\"Year\"], winners[\"imdbRating\"], marker=\"o\", linestyle=\"-\")\n",
    "plt.title(\"IMDb Rating of Best Picture Winners Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"IMDb Rating\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goal: Word Cloud (Wikipedia Movie Summaries) ‚òÅÔ∏è\n",
    "Placeholder for future development. I plan to create word cloud for the plot summaries. If Wikipedia summaries are accessible, also generate a **word cloud** from commonly used words in movie descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample Wikipedia summary text (replace with actual summaries if available)\n",
    "# sample_text = \"This is a sample summary of a Best Picture-winning film. It tells the story of love, ambition, and success.\"\n",
    "\n",
    "# # Tokenize & remove stopwords\n",
    "# tokens = word_tokenize(sample_text.lower())\n",
    "# filtered_words = [word for word in tokens if word.isalnum() and word not in stopwords.words(\"english\")]\n",
    "\n",
    "# # Generate Word Cloud\n",
    "# wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(filtered_words))\n",
    "\n",
    "# # Display Word Cloud\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Word Cloud of Wikipedia Movie Summaries\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oscars = pd.read_csv(\"data/oscars.csv\", sep='\\t', on_bad_lines='skip')\n",
    "# oscars = oscars.dropna()\n",
    "# oscars = oscars.drop_duplicates()\n",
    "# oscars = oscars.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Store Data in SQLite Database\n",
    "# conn = sqlite3.connect(\"academy_awards.db\")\n",
    "# awards_df.to_sql(\"awards\", conn, if_exists=\"replace\", index=False)\n",
    "# speech_df.to_sql(\"speeches\", conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: SQL Queries & Analysis\n",
    "# ## Query genres of Best Picture winners over decades\n",
    "# query = \"\"\"\n",
    "# SELECT genre, COUNT(*) AS num_wins, strftime('%Y', award_year) AS decade\n",
    "# FROM awards\n",
    "# WHERE category = 'Best Picture'\n",
    "# GROUP BY genre, decade\n",
    "# ORDER BY decade ASC;\n",
    "# \"\"\"\n",
    "# genre_trends_df = pd.read_sql(query, conn)\n",
    "\n",
    "# ## Query word frequency in acceptance speeches\n",
    "# query = \"\"\"\n",
    "# SELECT cleaned_speech FROM speeches;\n",
    "# \"\"\"\n",
    "# speech_texts = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Analysis (examples)\n",
    "- In this analysis, we explored the relationship between the race of law enforcement officers and the race of the drivers they stop. Our goal was to see if there‚Äôs any indication of bias in traffic stops based on the racial identity of the officers. To do this, we used a chi-squared test for independence, which helps us understand whether there‚Äôs a meaningful connection between these two groups.\n",
    "\n",
    "### Results of the Chi-Squared Test\n",
    "- **Chi-Squared Statistic:** We calculated a chi-squared statistic of 122.92. This high number shows that there‚Äôs a significant difference between the actual number of stops for different racial groups and what we would expect to see if there were no connection between the officer's race and the driver's race. In other words, this suggests that the patterns we observe in the data are unlikely to be just a coincidence.\n",
    "\n",
    "- **P-Value:** The p-value we found was about 8.20e-17, which is extremely low. This tells us that the result is statistically significant since it‚Äôs much lower than the usual thresholds (like 0.05 or 0.01). A low p-value means we have strong evidence against the idea that there‚Äôs no connection between the officer's race and the driver's race.\n",
    "\n",
    "### Interpretation of Findings\n",
    "- The results show a strong connection between the race of the officer and the race of the driver being stopped. This means that a driver's chances of being stopped may change depending on the officer's race, suggesting there might be some bias in how traffic stops are carried out.\n",
    "\n",
    "### Implications\n",
    "- These findings are important for understanding how race plays a role in law enforcement. They suggest that different racial groups might be treated differently by officers during traffic stops. It's crucial to address these biases to ensure fairness and equality in policing.\n",
    "\n",
    "### Conclusion\n",
    "- The strong evidence from the chi-squared statistic and p-value emphasizes the importance of further examining law enforcement practices. Police leaders and community advocacy groups should take these findings into account when reviewing policies and training programs designed to reduce racial bias in policing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
