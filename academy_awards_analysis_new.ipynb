{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academy Awards Analysis 🎬\n",
    "## Investigating Trends in Oscar-Winning Movies\n",
    "### Author: Judd Jacobs\n",
    "\n",
    "This project analyzes historical **Academy Award-winning films** using data from **Wikipedia**, **The Movie Database (TMDb)**, and **The Open Movie Database (OMDb)**.\n",
    "\n",
    "## **Key Analysis Areas**\n",
    "- **Best Picture trends by genre** (from Wikipedia Scrape & TMDb API) 🏆\n",
    "- **Box office revenue & IMDb ratings** (OMDb API) 🎭\n",
    "- **Long-term trends in Oscar-winning films** 📈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1:** Import necessary Python Libraries 💽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from urllib.parse import quote\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "# # Import NLTK libraries are currently a strech goal for future development\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# # Ensure necessary NLTK components are downloaded\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2:** Data Acquisition 🗂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scrape** Wikipedia\n",
    "Extract **Best Picture winners**, nominees, and relevant metadata availble on Wikipedia here: https://en.wikipedia.org/wiki/List_of_Academy_Award–winning_films\n",
    "- **`pandas.read_html()`** to extract the table structure.\n",
    "- **`BeautifulSoup`** to identify \"winning\" rows based on Wikipedia background color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Film  Year Awards Nominations\n",
      "0           Anora  2024      5           6\n",
      "1   The Brutalist  2024      3          10\n",
      "2    Emilia Pérez  2024      2          13\n",
      "3          Wicked  2024      2          10\n",
      "4  Dune: Part Two  2024      2           5\n",
      "Film           object\n",
      "Year           object\n",
      "Awards         object\n",
      "Nominations    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Wikipedia URL for Best Picture winners\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_Academy_Award%E2%80%93winning_films\"\n",
    "\n",
    "# Use pandas to extract the table\n",
    "tables = pd.read_html(wiki_url)\n",
    "\n",
    "# Select the correct table, adjusting the index as needed\n",
    "best_picture_wikipedia = tables[0]\n",
    "\n",
    "# # Convert the table to a DataFrame - I may be able to remove this step\n",
    "# best_picture_wikipedia = pd.DataFrame(best_picture_wikipedia)\n",
    "\n",
    "# Print the first few rows to ensure the correct table was selected\n",
    "print(best_picture_wikipedia.head())\n",
    "print(best_picture_wikipedia.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Film  Year Awards Nominations   Status\n",
      "0           Anora  2024      5           6   Winner\n",
      "1   The Brutalist  2024      3          10  Nominee\n",
      "2    Emilia Pérez  2024      2          13  Nominee\n",
      "3          Wicked  2024      2          10  Nominee\n",
      "4  Dune: Part Two  2024      2           5  Nominee\n",
      "Film           object\n",
      "Year           object\n",
      "Awards         object\n",
      "Nominations    object\n",
      "Status         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Find the Wikipedia table with BeautifulSoup\n",
    "response_wikipedia = requests.get(wiki_url)\n",
    "soup_wikipedia = BeautifulSoup(response_wikipedia.text, \"html.parser\")\n",
    "wikipedia_table = soup_wikipedia.find_all(\"table\", {\"class\": \"wikitable\"})[0]\n",
    "\n",
    "# Extract all rows\n",
    "rows = wikipedia_table.find_all(\"tr\")\n",
    "\n",
    "# List to store \"Winner\" status\n",
    "winning_status = []\n",
    "\n",
    "# Loop through rows and check for background color \"#EEDD82\" skipping the header row\n",
    "for row in rows[1:]:\n",
    "    style = row.get(\"style\", \"\")\n",
    "    \n",
    "    # Check if the row has the background color for winners and remove spaces for consistency\n",
    "    if \"background:#EEDD82\" in style.replace(\" \", \"\"):\n",
    "        winning_status.append(\"Winner\")\n",
    "    else:\n",
    "        winning_status.append(\"Nominee\")\n",
    "\n",
    "# Ensure the list length matches the DataFrame\n",
    "if len(winning_status) == len(best_picture_wikipedia):\n",
    "    best_picture_wikipedia[\"Status\"] = winning_status\n",
    "else:\n",
    "    print(\"List length does not match DataFrame length\")\n",
    "\n",
    "# # Normalize \"Status\" column and filter only winners\n",
    "# best_picture_winners = best_picture_wikipedia[best_picture_wikipedia[\"Status\"] == \"Winner\"]\n",
    "\n",
    "# # Convert the table to a DataFrame\n",
    "# best_picture_wikipedia = pd.DataFrame(best_picture_wikipedia)\n",
    "\n",
    "# Display updated DataFrame\n",
    "print(best_picture_wikipedia.head())\n",
    "print(best_picture_wikipedia.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Genres from TMDb API 🎭\n",
    "Use **The Movie Database (TMDb) API** to retrieve **movie genres** for Best Picture winners listed in Wikipedia Dataset.\n",
    "\n",
    "⚠️ Note: the cell below may take up to two minutes, or longer, to load. ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Title                        Genres\n",
      "0           Anora      [Drama, Comedy, Romance]\n",
      "1   The Brutalist                       [Drama]\n",
      "2    Emilia Pérez             [Drama, Thriller]\n",
      "3          Wicked     [Fantasy, Romance, Drama]\n",
      "4  Dune: Part Two  [Science Fiction, Adventure]\n",
      "Title     object\n",
      "Genres    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the TMDB API keys stored in the .env file and define them here\n",
    "tmdb_api_key = os.getenv('TMDB_API_KEY')\n",
    "tmdb_api_read_access_token = os.getenv('TMBD_API_READ_ACCESS_TOKEN')\n",
    "\n",
    "tmdb_api_base_url = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "# Function to get genre mappings (ID -> Name)\n",
    "def get_genre_mapping() -> dict:\n",
    "    url = f\"{tmdb_api_base_url}/genre/movie/list?language=en-US\"\n",
    "    headers = {\"accept\": \"application/json\", \"Authorization\": f\"Bearer {tmdb_api_read_access_token}\"}\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"genres\" in data:\n",
    "        return {genre[\"id\"]: genre[\"name\"] for genre in data[\"genres\"]}\n",
    "    return {}\n",
    "\n",
    "# Function to query TMDB API and get genre names for movies\n",
    "def get_movie_genres(film_titles) -> dict:\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {tmdb_api_read_access_token}\"\n",
    "        }\n",
    "    \n",
    "    # Fetch genre ID-to-name mapping\n",
    "    genre_mapping = get_genre_mapping()\n",
    "\n",
    "    # Store results\n",
    "    movie_genres = {}\n",
    "\n",
    "    for title in film_titles:\n",
    "        # Encode spaces and special characters for use in URL\n",
    "        encoded_title = quote(title)\n",
    "        \n",
    "        url = f\"{tmdb_api_base_url}/search/movie?query={encoded_title}&include_adult=false&language=en-US&page=1\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = response.json()\n",
    "        \n",
    "        if \"results\" in data and data[\"results\"]:\n",
    "            # Ensure exact match\n",
    "            exact_match = next((movie for movie in data[\"results\"] if movie[\"title\"] == title), None)\n",
    "            \n",
    "            if exact_match:\n",
    "                genre_ids = exact_match[\"genre_ids\"]\n",
    "                genre_names = [genre_mapping.get(gid, \"Unknown Genre\") for gid in genre_ids]\n",
    "                movie_genres[title] = genre_names\n",
    "            else:\n",
    "                movie_genres[title] = [\"No exact match found\"]\n",
    "        else:\n",
    "            movie_genres[title] = [\"No results found\"]\n",
    "    \n",
    "    return movie_genres\n",
    "\n",
    "# Create a List of the movie titles from extracted Wikipedia data\n",
    "movie_titles = best_picture_wikipedia[\"Film\"].tolist()\n",
    "\n",
    "# Get genre names for each movie\n",
    "tmdb_genre_results = get_movie_genres(movie_titles)\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "tmdb_genre_results = pd.DataFrame(list(tmdb_genre_results.items()), columns=[\"Title\", \"Genres\"])\n",
    "print(tmdb_genre_results.head())\n",
    "print(tmdb_genre_results.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Data from Wikipedia and TMDb 🎞️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_picture_wikipedia columns: ['Film', 'Year', 'Awards', 'Nominations', 'Status']\n",
      "tmdb_genre_results columns: ['Title', 'Genres']\n"
     ]
    }
   ],
   "source": [
    "# Confirm column names for both DataFrames\n",
    "print(\"best_picture_wikipedia columns:\", best_picture_wikipedia.columns.tolist())\n",
    "print(\"tmdb_genre_results columns:\", tmdb_genre_results.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Film  Year Awards Nominations   Status   Genres  Action  \\\n",
      "0          Anora  2024      5           6   Winner    Drama       0   \n",
      "0          Anora  2024      5           6   Winner   Comedy       0   \n",
      "0          Anora  2024      5           6   Winner  Romance       0   \n",
      "1  The Brutalist  2024      3          10  Nominee    Drama       0   \n",
      "2   Emilia Pérez  2024      2          13  Nominee    Drama       0   \n",
      "\n",
      "   Adventure  Animation  Comedy  ...  Music  Mystery  No exact match found  \\\n",
      "0          0          0       0  ...      0        0                     0   \n",
      "0          0          0       1  ...      0        0                     0   \n",
      "0          0          0       0  ...      0        0                     0   \n",
      "1          0          0       0  ...      0        0                     0   \n",
      "2          0          0       0  ...      0        0                     0   \n",
      "\n",
      "   No results found  Romance  Science Fiction  TV Movie  Thriller  War  \\\n",
      "0                 0        0                0         0         0    0   \n",
      "0                 0        0                0         0         0    0   \n",
      "0                 0        1                0         0         0    0   \n",
      "1                 0        0                0         0         0    0   \n",
      "2                 0        0                0         0         0    0   \n",
      "\n",
      "   Western  \n",
      "0        0  \n",
      "0        0  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Index(['Film', 'Year', 'Awards', 'Nominations', 'Status', 'Genres', 'Action',\n",
      "       'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
      "       'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery',\n",
      "       'No exact match found', 'No results found', 'Romance',\n",
      "       'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge best_picture_wikipedia and tmdb_genre_results DataFrames on \"Film\"/\"Title\"\n",
    "best_picture_merged = best_picture_wikipedia.merge(\n",
    "    tmdb_genre_results,\n",
    "    left_on=\"Film\",\n",
    "    right_on=\"Title\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Drop the now redundant \"Title\" column\n",
    "best_picture_merged.drop(\"Title\", axis=1, inplace=True)\n",
    "\n",
    "# Split the genres into separate columns\n",
    "best_picture_merged = best_picture_merged.explode(\"Genres\")\n",
    "best_picture_merged = pd.concat([best_picture_merged, best_picture_merged[\"Genres\"].str.get_dummies()], axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(best_picture_merged.head())\n",
    "print(best_picture_merged.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Metadata from OMDb API 💸\n",
    "Use **OMDb API** to fetch **box office revenue** and other metadata for Best Picture winners and combine with merged Wikipedia and TMDb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7399547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMDb API Error for 'War Is Over! Inspired by the Music of John and Yoko' → 'War Is Over! Inspired by the Music of John and Yoko': Movie not found!\n",
      "OMDb API Error for 'Flesh and Sand (Carne y arena)' → 'Flesh and Sand': Movie not found!\n",
      "OMDb API Error for 'La Maison en Petits Cubes' → 'La Maison en Petits Cubes': Movie not found!\n",
      "OMDb API Error for 'Le Mozart des pickpockets' → 'Le Mozart des pickpockets': Movie not found!\n",
      "OMDb API Error for 'Lemony Snicket's A Series of Unfortunate Events' → 'Lemony Snicket's A Series of Unfortunate Events': Movie not found!\n",
      "OMDb API Error for 'Il Postino: The Postman' → 'Il Postino: The Postman': Movie not found!\n",
      "OMDb API Error for 'Hôtel Terminus: The Life and Times of Klaus Barbie' → 'Hôtel Terminus: The Life and Times of Klaus Barbie': Movie not found!\n",
      "OMDb API Error for 'The Ten-Year Lunch' → 'The Ten-Year Lunch': Movie not found!\n",
      "OMDb API Error for 'Just Another Missing Kid' → 'Just Another Missing Kid': Movie not found!\n",
      "OMDb API Error for 'To Begin Again (Volver a empezar)' → 'To Begin Again': Movie not found!\n",
      "OMDb API Error for 'Fellini's Casanova (Il Casanova di Federico Fellini)' → 'Fellini's Casanova': Movie not found!\n",
      "OMDb API Error for 'This Tiny World' → 'This Tiny World': Movie not found!\n",
      "OMDb API Error for 'Czechoslovakia 1968' → 'Czechoslovakia 1968': Movie not found!\n",
      "OMDb API Error for 'A Herb Alpert and the Tijuana Brass Double Feature' → 'A Herb Alpert and the Tijuana Brass Double Feature': Movie not found!\n",
      "OMDb API Error for 'All That Money Can Buy' → 'All That Money Can Buy': Movie not found!\n",
      "OMDb API Error for 'Black Fox: The Rise and Fall of Adolf Hitler (The Black Fox)' → 'Black Fox: The Rise and Fall of Adolf Hitler': Movie not found!\n",
      "OMDb API Error for 'Helen Keller in Her Story (The Unconquered)' → 'Helen Keller in Her Story': Movie not found!\n",
      "OMDb API Error for 'In Beaver Valley' → 'In Beaver Valley': Movie not found!\n",
      "OMDb API Error for 'Serengeti Shall Not Die (Serengeti darf nicht sterben)' → 'Serengeti Shall Not Die': Movie not found!\n",
      "OMDb API Error for 'Sky Above and Mud Beneath (Le Ciel et la boue)' → 'Sky Above and Mud Beneath': Movie not found!\n",
      "            Film  Year                                          Awards  \\\n",
      "0          Anora  2024  Won 5 Oscars. 144 wins & 267 nominations total   \n",
      "0          Anora  2024  Won 5 Oscars. 144 wins & 267 nominations total   \n",
      "0          Anora  2024  Won 5 Oscars. 144 wins & 267 nominations total   \n",
      "1  The Brutalist  2024  Won 3 Oscars. 136 wins & 340 nominations total   \n",
      "2   Emilia Pérez  2024  Won 2 Oscars. 119 wins & 237 nominations total   \n",
      "\n",
      "  Nominations   Status   Genres  Action  Adventure  Animation  Comedy  ...  \\\n",
      "0           6   Winner    Drama       0          0          0       0  ...   \n",
      "0           6   Winner   Comedy       0          0          0       1  ...   \n",
      "0           6   Winner  Romance       0          0          0       0  ...   \n",
      "1          10  Nominee    Drama       0          0          0       0  ...   \n",
      "2          13  Nominee    Drama       0          0          0       0  ...   \n",
      "\n",
      "   Metascore  imdbRating  imdbVotes      imdbID   Type  DVD    BoxOffice  \\\n",
      "0         91         7.8    122,308  tt28607951  movie  N/A  $16,300,129   \n",
      "0         91         7.8    122,308  tt28607951  movie  N/A  $16,300,129   \n",
      "0         91         7.8    122,308  tt28607951  movie  N/A  $16,300,129   \n",
      "1         90         7.5     65,135   tt8999762  movie  N/A  $16,025,241   \n",
      "2         70         5.4     80,230  tt20221436  movie  N/A          N/A   \n",
      "\n",
      "   Production  Website  Response  \n",
      "0         N/A      N/A      True  \n",
      "0         N/A      N/A      True  \n",
      "0         N/A      N/A      True  \n",
      "1         N/A      N/A      True  \n",
      "2         N/A      N/A      True  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Pull in OMDb API Key\n",
    "omdb_api_key = os.getenv(\"OMDB_API_KEY\")\n",
    "\n",
    "# Local cache file\n",
    "cache_file = \"omdb_cache.json\"\n",
    "\n",
    "# Load cache if it exists\n",
    "if os.path.exists(cache_file):\n",
    "    with open(cache_file, \"r\") as f:\n",
    "        omdb_cache = json.load(f)\n",
    "else:\n",
    "    omdb_cache = {}\n",
    "\n",
    "# Function to clean movie titles\n",
    "def clean_title(title: str) -> str:\n",
    "    return re.sub(r'\\s*\\(.*?\\)', '', title).strip()\n",
    "\n",
    "# Function to fetch metadata (if not cached)\n",
    "def get_full_movie_metadata(movie_title, api_key) -> dict:\n",
    "    cleaned_title = clean_title(movie_title)\n",
    "\n",
    "    # Use cleaned title as cache key\n",
    "    if cleaned_title in omdb_cache:\n",
    "        return omdb_cache[cleaned_title]\n",
    "\n",
    "    encoded_title = quote(cleaned_title)\n",
    "    omdb_url = f\"http://www.omdbapi.com/?t={encoded_title}&apikey={api_key}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(omdb_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if \"Error\" in data:\n",
    "            print(f\"OMDb API Error for '{movie_title}' → '{cleaned_title}': {data['Error']}\")\n",
    "            data = {}\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Timeout error for '{movie_title}' → '{cleaned_title}'. Skipping...\")\n",
    "        data = {}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request failed for '{movie_title}' → '{cleaned_title}': {e}\")\n",
    "        data = {}\n",
    "    except ValueError:\n",
    "        print(f\"Invalid JSON response for '{movie_title}' → '{cleaned_title}'.\")\n",
    "        data = {}\n",
    "\n",
    "    # Store in cache regardless of success/failure\n",
    "    omdb_cache[cleaned_title] = data\n",
    "    return data\n",
    "\n",
    "# Populate DataFrame using cached API responses\n",
    "def populate_metadata(movie_df, title_column, metadata_func, metadata_fields, api_key) -> pd.DataFrame:\n",
    "    for field in metadata_fields:\n",
    "        if field not in movie_df.columns:\n",
    "            movie_df[field] = \"\"\n",
    "\n",
    "    for index, row in movie_df.iterrows():\n",
    "        title = row[title_column]\n",
    "        metadata = metadata_func(title, api_key)\n",
    "        for field in metadata_fields:\n",
    "            value = metadata.get(field, \"N/A\")\n",
    "            if isinstance(value, (dict, list)):\n",
    "                value = str(value)\n",
    "            movie_df.at[index, field] = value\n",
    "\n",
    "    return movie_df\n",
    "\n",
    "# Fields to add to the DataFrame\n",
    "metadata_fields = [\n",
    "    \"Title\", \"Year\", \"Rated\", \"Released\", \"Runtime\", \"Genre\", \"Director\", \"Writer\", \"Actors\", \"Plot\",\n",
    "    \"Language\", \"Country\", \"Awards\", \"Poster\", \"Ratings\", \"Metascore\", \"imdbRating\", \"imdbVotes\",\n",
    "    \"imdbID\", \"Type\", \"DVD\", \"BoxOffice\", \"Production\", \"Website\", \"Response\"\n",
    "]\n",
    "\n",
    "# Run metadata enrichment\n",
    "best_picture_all = populate_metadata(\n",
    "    best_picture_merged.copy(),\n",
    "    title_column=\"Film\",\n",
    "    metadata_func=get_full_movie_metadata,\n",
    "    metadata_fields=metadata_fields,\n",
    "    api_key=omdb_api_key\n",
    ")\n",
    "\n",
    "# Save updated cache\n",
    "with open(cache_file, \"w\") as f:\n",
    "    json.dump(omdb_cache, f, indent=2)\n",
    "\n",
    "# Preview\n",
    "print(best_picture_all.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3:** Data Cleaning & Storage 🛠\n",
    "Merged data will have some cleaning applied and then the cleaned dataset will be stored in a local **SQLite database**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the merged raw dataset to avoid mutating the original\n",
    "best_picture_all_clean = best_picture_all.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows based on columns: 'Response', 'Type'\n",
    "best_picture_all_clean = best_picture_all_clean[(best_picture_all_clean['Response'].str.contains(\"True\", regex=False, na=False, case=False))\n",
    "                                                 & (best_picture_all['Type'].str.contains(\"movie\", regex=False, na=False, case=False))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary or empty columns\n",
    "best_picture_all_clean.drop(columns=[\"Website\", \"DVD\", \"Production\"], inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_money(val) -> float:\n",
    "    if pd.isna(val) or val == \"N/A\":\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(str(val).replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def clean_votes(val) -> float:\n",
    "    if pd.isna(val) or val == \"N/A\":\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(str(val).replace(\",\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Execute the cleaning functions\n",
    "best_picture_all_clean[\"BoxOffice\"] = best_picture_all_clean[\"BoxOffice\"].apply(clean_money)\n",
    "\n",
    "# Apply to imdbVotes only (since it's a string with commas)\n",
    "best_picture_all_clean[\"imdbVotes\"] = best_picture_all_clean[\"imdbVotes\"].apply(clean_votes)\n",
    "\n",
    "# Conversion for numeric columns stored as text\n",
    "numeric_columns = [\"imdbRating\", \"Metascore\"]\n",
    "best_picture_all_clean[numeric_columns] = best_picture_all_clean[numeric_columns].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert Runtime from string to integer minutes\n",
    "def extract_runtime(runtime_str):\n",
    "    if pd.isna(runtime_str) or runtime_str == \"N/A\":\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(runtime_str.split(\" \")[0])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "best_picture_all_clean[\"Runtime\"] = best_picture_all_clean[\"Runtime\"].apply(extract_runtime)\n",
    "\n",
    "# Convert \"N/A\" to NaN across object columns\n",
    "best_picture_all_clean.replace(\"N/A\", np.nan, inplace=True)\n",
    "\n",
    "# Convert Year to integer\n",
    "best_picture_all_clean[\"Year\"] = pd.to_numeric(best_picture_all_clean[\"Year\"], errors=\"coerce\")\n",
    "\n",
    "# Reset index (optional)\n",
    "best_picture_all_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Preview cleaned DataFrame\n",
    "best_picture_all_clean.info()\n",
    "best_picture_all_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter rows based on columns: 'Response', 'Type'\n",
    "best_picture_all_clean = best_picture_all_clean[(best_picture_all_clean['Response'].str.contains(\"True\", regex=False, na=False, case=False))\n",
    "                                                 & (best_picture_all['Type'].str.contains(\"movie\", regex=False, na=False, case=False))]\n",
    "\n",
    "# Drop unnecessary or empty columns\n",
    "best_picture_all_clean.drop(columns=[\"Website\", \"DVD\", \"Production\"], inplace=True, errors='ignore')\n",
    "\n",
    "# Remove duplicates based on Film + Year\n",
    "best_picture_all_clean.drop_duplicates(subset=[\"Film\", \"Year\"], keep=\"first\", inplace=True)\n",
    "\n",
    "# Clean up BoxOffice and imdbVotes\n",
    "def clean_money(val):\n",
    "    if pd.isna(val) or val == \"N/A\":\n",
    "        return np.nan\n",
    "    return int(val.replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "\n",
    "def clean_votes(val):\n",
    "    if pd.isna(val) or val == \"N/A\":\n",
    "        return np.nan\n",
    "    return int(val.replace(\",\", \"\"))\n",
    "\n",
    "best_picture_all_clean[\"BoxOffice\"] = best_picture_all_clean[\"BoxOffice\"].apply(clean_money)\n",
    "best_picture_all_clean[\"imdbVotes\"] = best_picture_all_clean[\"imdbVotes\"].apply(clean_votes)\n",
    "\n",
    "# Convert Runtime from string to integer minutes\n",
    "def extract_runtime(runtime_str):\n",
    "    if pd.isna(runtime_str) or runtime_str == \"N/A\":\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(runtime_str.split(\" \")[0])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "best_picture_all_clean[\"Runtime\"] = best_picture_all_clean[\"Runtime\"].apply(extract_runtime)\n",
    "\n",
    "# Convert \"N/A\" to NaN across object columns\n",
    "best_picture_all_clean.replace(\"N/A\", np.nan, inplace=True)\n",
    "\n",
    "# Convert Year to integer\n",
    "best_picture_all_clean[\"Year\"] = pd.to_numeric(best_picture_all_clean[\"Year\"], errors=\"coerce\")\n",
    "\n",
    "# Reset index (optional)\n",
    "best_picture_all_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Preview cleaned DataFrame\n",
    "best_picture_all_clean.info()\n",
    "best_picture_all_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter rows based on columns: 'Response', 'Type'\n",
    "best_picture_all_clean = best_picture_all_clean[(best_picture_all_clean['Response'].str.contains(\"True\", regex=False, na=False, case=False))\n",
    "                                                 & (best_picture_all['Type'].str.contains(\"movie\", regex=False, na=False, case=False))]\n",
    "\n",
    "# Drop unnecessary or empty columns\n",
    "best_picture_all_clean.drop(columns=[\"Website\", \"DVD\", \"Production\"], inplace=True, errors='ignore')\n",
    "\n",
    "# Remove duplicates based on Film + Year\n",
    "best_picture_all_clean.drop_duplicates(subset=[\"Film\", \"Year\"], keep=\"first\", inplace=True)\n",
    "\n",
    "# Clean up BoxOffice and imdbVotes\n",
    "def clean_money(val):\n",
    "    if pd.isna(val) or val == \"N/A\":\n",
    "        return np.nan\n",
    "    return int(val.replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "\n",
    "def clean_votes(val):\n",
    "    if pd.isna(val) or val == \"N/A\":\n",
    "        return np.nan\n",
    "    return int(val.replace(\",\", \"\"))\n",
    "\n",
    "best_picture_all_clean[\"BoxOffice\"] = best_picture_all_clean[\"BoxOffice\"].apply(clean_money)\n",
    "best_picture_all_clean[\"imdbVotes\"] = best_picture_all_clean[\"imdbVotes\"].apply(clean_votes)\n",
    "\n",
    "# Convert Runtime from string to integer minutes\n",
    "def extract_runtime(runtime_str):\n",
    "    if pd.isna(runtime_str) or runtime_str == \"N/A\":\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(runtime_str.split(\" \")[0])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "best_picture_all_clean[\"Runtime\"] = best_picture_all_clean[\"Runtime\"].apply(extract_runtime)\n",
    "\n",
    "# Convert \"N/A\" to NaN across object columns\n",
    "best_picture_all_clean.replace(\"N/A\", np.nan, inplace=True)\n",
    "\n",
    "# Convert Year to integer\n",
    "best_picture_all_clean[\"Year\"] = pd.to_numeric(best_picture_all_clean[\"Year\"], errors=\"coerce\")\n",
    "\n",
    "# Reset index (optional)\n",
    "best_picture_all_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Preview cleaned DataFrame\n",
    "best_picture_all_clean.info()\n",
    "best_picture_all_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cleaned data to local SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect(\"academy_awards.db\")\n",
    "# merged_df.to_sql(\"best_picture_winners\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# print(\"Data successfully stored in SQLite database!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are cells that might be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell was moved down from above and may eventually be removed\n",
    "# # Function to store movie data in SQLite\n",
    "# def store_movie_data(movie_data) -> None:\n",
    "#     # Create/connect to the database\n",
    "#     conn = sqlite3.connect(\"academy_awards.db\")\n",
    "#     cursor = conn.cursor()\n",
    "\n",
    "#     # Create table if it doesn't exist\n",
    "#     cursor.execute('''\n",
    "#         CREATE TABLE IF NOT EXISTS movies (\n",
    "#             id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#             film TEXT,\n",
    "#             release_date TEXT,\n",
    "#             overview TEXT,\n",
    "#             vote_average REAL,\n",
    "#             tmdb_id INTEGER UNIQUE\n",
    "#         )\n",
    "#     ''')\n",
    "\n",
    "#     # Extract movie details from API response\n",
    "#     if movie_data and movie_data.get(\"results\"):\n",
    "#         for movie in movie_data[\"results\"]:\n",
    "#             tmdb_id = movie.get(\"id\")\n",
    "#             title = movie.get(\"title\", \"Unknown\")\n",
    "#             release_date = movie.get(\"release_date\", \"N/A\")\n",
    "#             overview = movie.get(\"overview\", \"No description available.\")\n",
    "#             vote_average = movie.get(\"vote_average\", 0.0)\n",
    "\n",
    "#             # Insert or ignore if the movie already exists (prevents duplicate entries)\n",
    "#             cursor.execute('''\n",
    "#                 INSERT OR IGNORE INTO movies (tmdb_id, title, release_date, overview, vote_average)\n",
    "#                 VALUES (?, ?, ?, ?, ?)\n",
    "#             ''', (tmdb_id, title, release_date, overview, vote_average))\n",
    "\n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "\n",
    "# # Loop through each movie, fetch data, and store in the database\n",
    "# for movie in movie_titles:\n",
    "#     data = fetch_movie_data(movie)\n",
    "#     if data:\n",
    "#         store_movie_data(data)\n",
    "\n",
    "# print(\"Movie data successfully stored in SQLite database!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connect to the database\n",
    "# conn = sqlite3.connect(\"academy_awards.db\")\n",
    "\n",
    "# # Create a cursor object\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Execute the query and fetch all rows\n",
    "# cursor.execute(\"SELECT * FROM movies\")\n",
    "# rows = cursor.fetchall()\n",
    "\n",
    "# # Print the results\n",
    "# for row in rows:\n",
    "#     print(row)\n",
    "\n",
    "# # Close the connection\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis 📊\n",
    "We will explore trends in **Best Picture winners** by genre and other relevant statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Office Ratings 💰\n",
    "We will analyze **box office revenue** and number of nominations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scatter plot: Box Office Revenue vs IMDb Ratings\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(x=kaggle_df[\"BoxOffice\"], y=kaggle_df[\"IMDb Rating\"], hue=kaggle_df[\"Year\"], palette=\"coolwarm\")\n",
    "# plt.xlabel(\"Box Office Revenue (in millions)\")\n",
    "# plt.ylabel(\"IMDb Rating\")\n",
    "# plt.title(\"Box Office Revenue vs IMDb Ratings for Best Picture Winners\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goal: Word Cloud (Wikipedia Movie Summaries) ☁️\n",
    "If Wikipedia summaries are accessible, generate a **word cloud** from commonly used words in movie descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample Wikipedia summary text (replace with actual summaries if available)\n",
    "# sample_text = \"This is a sample summary of a Best Picture-winning film. It tells the story of love, ambition, and success.\"\n",
    "\n",
    "# # Tokenize & remove stopwords\n",
    "# tokens = word_tokenize(sample_text.lower())\n",
    "# filtered_words = [word for word in tokens if word.isalnum() and word not in stopwords.words(\"english\")]\n",
    "\n",
    "# # Generate Word Cloud\n",
    "# wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(filtered_words))\n",
    "\n",
    "# # Display Word Cloud\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Word Cloud of Wikipedia Movie Summaries\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oscars = pd.read_csv(\"data/oscars.csv\", sep='\\t', on_bad_lines='skip')\n",
    "# oscars = oscars.dropna()\n",
    "# oscars = oscars.drop_duplicates()\n",
    "# oscars = oscars.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Store Data in SQLite Database\n",
    "# conn = sqlite3.connect(\"academy_awards.db\")\n",
    "# awards_df.to_sql(\"awards\", conn, if_exists=\"replace\", index=False)\n",
    "# speech_df.to_sql(\"speeches\", conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: SQL Queries & Analysis\n",
    "# ## Query genres of Best Picture winners over decades\n",
    "# query = \"\"\"\n",
    "# SELECT genre, COUNT(*) AS num_wins, strftime('%Y', award_year) AS decade\n",
    "# FROM awards\n",
    "# WHERE category = 'Best Picture'\n",
    "# GROUP BY genre, decade\n",
    "# ORDER BY decade ASC;\n",
    "# \"\"\"\n",
    "# genre_trends_df = pd.read_sql(query, conn)\n",
    "\n",
    "# ## Query word frequency in acceptance speeches\n",
    "# query = \"\"\"\n",
    "# SELECT cleaned_speech FROM speeches;\n",
    "# \"\"\"\n",
    "# speech_texts = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Analysis (examples)\n",
    "- In this analysis, we explored the relationship between the race of law enforcement officers and the race of the drivers they stop. Our goal was to see if there’s any indication of bias in traffic stops based on the racial identity of the officers. To do this, we used a chi-squared test for independence, which helps us understand whether there’s a meaningful connection between these two groups.\n",
    "\n",
    "### Results of the Chi-Squared Test\n",
    "- **Chi-Squared Statistic:** We calculated a chi-squared statistic of 122.92. This high number shows that there’s a significant difference between the actual number of stops for different racial groups and what we would expect to see if there were no connection between the officer's race and the driver's race. In other words, this suggests that the patterns we observe in the data are unlikely to be just a coincidence.\n",
    "\n",
    "- **P-Value:** The p-value we found was about 8.20e-17, which is extremely low. This tells us that the result is statistically significant since it’s much lower than the usual thresholds (like 0.05 or 0.01). A low p-value means we have strong evidence against the idea that there’s no connection between the officer's race and the driver's race.\n",
    "\n",
    "### Interpretation of Findings\n",
    "- The results show a strong connection between the race of the officer and the race of the driver being stopped. This means that a driver's chances of being stopped may change depending on the officer's race, suggesting there might be some bias in how traffic stops are carried out.\n",
    "\n",
    "### Implications\n",
    "- These findings are important for understanding how race plays a role in law enforcement. They suggest that different racial groups might be treated differently by officers during traffic stops. It's crucial to address these biases to ensure fairness and equality in policing.\n",
    "\n",
    "### Conclusion\n",
    "- The strong evidence from the chi-squared statistic and p-value emphasizes the importance of further examining law enforcement practices. Police leaders and community advocacy groups should take these findings into account when reviewing policies and training programs designed to reduce racial bias in policing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
